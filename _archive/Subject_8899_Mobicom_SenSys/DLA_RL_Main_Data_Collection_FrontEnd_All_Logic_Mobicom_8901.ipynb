{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL workflow for personalized question generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There will be a q table for 20 items and q tables for each item that has more than 1 question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The way to ask questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model names:\n",
    "03-22-2022: davinci:ft-personal-2022-03-22-01-51-13\n",
    "03-29-2022: curie:ft-personal-2022-03-29-00-33-49\n",
    "04-07-2022: davinci:ft-personal-2022-04-07-05-39-11\n",
    "04-11-2022: davinci:ft-personal-2022-04-11-23-57-59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "#import matplotlib.pyplot as plt\n",
    "# data = pd.read_csv('record.csv')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import random\n",
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectID = str(8901)#str(input(\"please enter subject number\"))\n",
    "filename =  \"question_lib_v2_\"+subjectID+\".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Question</th>\n",
       "      <th>Question_Lock</th>\n",
       "      <th>Resp</th>\n",
       "      <th>Resp_Lock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Goodbye. We will do the screening in another t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Not today.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Question  \\\n",
       "0           0  Goodbye. We will do the screening in another t...   \n",
       "\n",
       "   Question_Lock         Resp  Resp_Lock  \n",
       "0              0   Not today.          1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure that the locks are ready to go\n",
    "data = pd.read_csv('record.csv')\n",
    "data['Question_Lock'][0]=0\n",
    "data['Resp_Lock'][0]=1\n",
    "header = [\"Question\", \"Question_Lock\", \"Resp\", \"Resp_Lock\"]\n",
    "data.to_csv('record.csv', columns = header)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lower fedality sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = \"davinci:ft-personal-2022-05-30-20-14-19\" #\"\"davinci:ft-personal-2022-05-21-22-14-23\"# \"davinci:ft-personal-2022-04-11-23-57-59\"\n",
    "report_file_name = \"data_collection_results/Report_\"+subjectID+'_'+str(time.time())+\".csv\"\n",
    "notes_file_name = \"data_collection_results/Notes_\"+subjectID+'_'+str(time.time())+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# import sounddevice as sd\n",
    "# from scipy.io.wavfile import write\n",
    "# import wavio as wv\n",
    "\n",
    "# from google.cloud import speech\n",
    "import os\n",
    "# import google.cloud.texttospeech as tts\n",
    "#from playsound import playsound\n",
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "np.random.seed(2)  # reproducible\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"platinum-scout-key.json\"\n",
    "ITEM_N_STATES = 20   # initial state + DLA_1 to DLA_18 + additional question\n",
    "ITEM_ACTIONS = ['{0}'.format(element) for element in np.arange(0, ITEM_N_STATES)]    # available actions\n",
    "ITEM_IMPORTANCE = [0, 5, 4, 4, 2, 5, 2, 2, 1, 3, 4, 3, 1, 4, 2, 4, 3, 1, 4, 4]  # importance rated by Vera\n",
    "NUMBER_QUESTIONS = [0, 4, 1, 2, 2, 5, 1, 1, 1, 2, 3, 2, 1, 1, 3, 2, 1, 3, 1, 1] # number of questions in each item\n",
    "QUESTIONS_IN_ITEM = []\n",
    "EPSILON = 0.9   # greedy police\n",
    "ALPHA = 0.1     # learning rate\n",
    "GAMMA = 0.9    # discount factor\n",
    "MAX_EPISODES = 13   # maximum episodes\n",
    "FRESH_TIME = 0.3    # fresh time for one move\n",
    "US_speakers = ['en-US-Standard-A',\n",
    " 'en-US-Standard-B',\n",
    " 'en-US-Standard-C',\n",
    " 'en-US-Standard-D',\n",
    " 'en-US-Standard-E',\n",
    " 'en-US-Standard-F',\n",
    " 'en-US-Standard-G',\n",
    " 'en-US-Standard-H',\n",
    " 'en-US-Standard-I',\n",
    " 'en-US-Standard-J',\n",
    " 'en-US-Wavenet-A',\n",
    " 'en-US-Wavenet-B',\n",
    " 'en-US-Wavenet-C',\n",
    " 'en-US-Wavenet-D',\n",
    " 'en-US-Wavenet-E',\n",
    " 'en-US-Wavenet-F',\n",
    " 'en-US-Wavenet-G',\n",
    " 'en-US-Wavenet-H',\n",
    " 'en-US-Wavenet-I',\n",
    " 'en-US-Wavenet-J']\n",
    "\n",
    "# Opening JSON file\n",
    "f = open(filename)\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "question_lib = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_synonymous_sentences(user_input):\n",
    "    return \"\"\"Generate synonymous sentences.\n",
    "\n",
    "    User: I am sad.\n",
    "    Answer: I feel sad.\n",
    "    User: I really enjoy my work recently.\n",
    "    Answer: I like my job a lot those days.\n",
    "    User: I have problem hearing you well.\n",
    "    Answer: I have problem understand you well.\n",
    "    User:{}\n",
    "    Answer:\"\"\".format(\n",
    "            user_input.capitalize()\n",
    "        )\n",
    "\n",
    "def generate_synonymous_sentences(question_text):\n",
    "    openai.api_key = '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'\n",
    "    user_input = question_text\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-001\",\n",
    "        prompt=generate_prompt_synonymous_sentences(user_input),\n",
    "        temperature=0.8,\n",
    "        max_tokens = 1000,\n",
    "    )\n",
    "    results = response.choices[0].text\n",
    "    print(response.choices[0].text)\n",
    "    return results\n",
    "\n",
    "def generate_prompt_therapist(user_input):\n",
    "    return \"\"\"Chat with people as a therapist.\n",
    "\n",
    "    User: I feel so depressed daily.\n",
    "    Answer: I am so sorry to hear that. It's OK to feel a little bit depressed but you need to figure out a way to makes you feel better. You can talk to a friend or family member. Or you can reach out to a therapist. And I am always here to support you.\n",
    "    User: I don't want to talk.\n",
    "    Answer: I get that you don’t want to have this conversation. But it's important to share your feelings with others and find out ways to make you feel better. \n",
    "    User: My partner wants to check my messages everyday.\n",
    "    Answer: When you having a controlling partner, you might want to know the following items. Understand Controlling Personality Types. Recognize the Part of You That Accepts Another's Control. Take Back Responsibility for Your Life. Decide Whether You Need or Want Controlling Men in Your Life. Know What You Want Out of Life. Learn and Practice Assertiveness. Set Healthy Boundaries.\n",
    "    User: I don't know what's going on with me.\n",
    "    Answer: It's fine not to know the reason why you don't feel well now. Doing medication might help you understand yourself better. Or you can reach out to your family members, friends, or therapist to help you out.\n",
    "    User:{}\n",
    "    Answer:\"\"\".format(\n",
    "            user_input.capitalize()\n",
    "        )\n",
    "\n",
    "def generate_therapist_chat(user_input):\n",
    "    openai.api_key = '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'\n",
    "    user_input = user_input\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-001\",\n",
    "        prompt=generate_prompt_therapist(user_input),\n",
    "        temperature=0.6,\n",
    "        max_tokens = 1000,\n",
    "    )\n",
    "    print(response.choices[0].text)\n",
    "    result = response.choices[0].text\n",
    "    return result\n",
    "\n",
    "def generate_prompt_change(user_input):\n",
    "    return \"\"\"　Change from first-person sentence to second-person.\n",
    "\n",
    "    User: I feel so depressed daily.\n",
    "    Answer: You feel so depressed daily.\n",
    "    User: I am so happy.\n",
    "    Answer: You are so happy.\n",
    "    User: I am under a lot of pressure.\n",
    "    Answer: You are under a lot of pressure.\n",
    "    User:{}\n",
    "    Answer:\"\"\".format(\n",
    "            user_input.capitalize()\n",
    "        )\n",
    "\n",
    "def generate_change(user_input): \n",
    "    openai.api_key = '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'\n",
    "    user_input = user_input\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-001\",\n",
    "        prompt=generate_prompt_change(user_input),\n",
    "        temperature=0.6,\n",
    "        max_tokens = 1000,\n",
    "    )\n",
    "    print(response.choices[0].text)\n",
    "    resp = response.choices[0].text\n",
    "    return resp\n",
    "\n",
    "\n",
    "def generate_prompt_change_positive(user_input):\n",
    "    return \"\"\"　Change from question to positive declarative sentence.\n",
    "\n",
    "    User: Do you have coping skills to help you calm down.\n",
    "    Answer: You have coping skills to help you calm down.\n",
    "    User: Do you have self-harming behaviours?\n",
    "    Answer: You have self-harming behaviours.\n",
    "    User: Are you involved in any legal issues recently?\n",
    "    Answer: You are involved in some legal issues recently.\n",
    "    User:{}\n",
    "    Answer:\"\"\".format(\n",
    "            user_input.capitalize()\n",
    "        )\n",
    "\n",
    "def generate_change_positive(user_input): \n",
    "    openai.api_key = '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'\n",
    "    user_input = user_input\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-001\",\n",
    "        prompt=generate_prompt_change_positive(user_input),\n",
    "        temperature=0.6,\n",
    "        max_tokens = 1000,\n",
    "    )\n",
    "    print(response.choices[0].text)\n",
    "    resp = response.choices[0].text\n",
    "    return resp\n",
    "\n",
    "def generate_prompt_change_negative(user_input):\n",
    "    return \"\"\"　Change from question to negative declarative sentence.\n",
    "\n",
    "    User: Do you have coping skills to help you calm down.\n",
    "    Answer: You don't have coping skills to help you calm down.\n",
    "    User: Do you feel productive?\n",
    "    Answer: You don't feel productive.\n",
    "    User: Have you done anything creative recently?\n",
    "    Answer: You haven't done anything creative recently.\n",
    "    User:{}\n",
    "    Answer:\"\"\".format(\n",
    "            user_input.capitalize()\n",
    "        )\n",
    "\n",
    "def generate_change_negative(user_input): \n",
    "    openai.api_key = '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'\n",
    "    user_input = user_input\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-001\",\n",
    "        prompt=generate_prompt_change_negative(user_input),\n",
    "        temperature=0.6,\n",
    "        max_tokens = 1000,\n",
    "    )\n",
    "    print(response.choices[0].text)\n",
    "    resp = response.choices[0].text\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I understand that you are worried about covid-19. It is a valid concern. However, it is important to try and stay positive and focus on things you can control. You can talk to your family and friends about your concerns. You can also reach out to a therapist if you need someone to talk to.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nI understand that you are worried about covid-19. It is a valid concern. However, it is important to try and stay positive and focus on things you can control. You can talk to your family and friends about your concerns. You can also reach out to a therapist if you need someone to talk to.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_therapist_chat(\"I am worried about COVID-19.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results():\n",
    "\n",
    "    fields = ['Item Label', 'Score', 'Notes'] \n",
    "\n",
    "#     # data rows of csv file \n",
    "#     rows = [ ['Nikhil', 'COE', '2', '9.0'], \n",
    "#              ['Sanchit', 'COE', '2', '9.1'], \n",
    "#              ['Aditya', 'IT', '2', '9.3'], \n",
    "#              ['Sagar', 'SE', '1', '9.5'], \n",
    "#              ['Prateek', 'MCE', '3', '7.8'], \n",
    "#              ['Sahil', 'EP', '2', '9.1']] \n",
    "\n",
    "    rows = []\n",
    "    cnt = 0\n",
    "    for i in range(1, len(question_lib)+1):\n",
    "        print(\"----\")\n",
    "        print(len(question_lib[str(i)]))\n",
    "        for ind in range(1, len(question_lib[str(i)])+1):\n",
    "            print(question_lib[str(i)][str(ind)][\"label\"], question_lib[str(i)][str(ind)][\"score\"])\n",
    "            items = [question_lib[str(i)][str(ind)][\"label\"], question_lib[str(i)][str(ind)][\"score\"], question_lib[str(i)][str(ind)][\"notes\"] ]\n",
    "            rows.append(items)\n",
    "            cnt += 1\n",
    "    print(rows)\n",
    "\n",
    "\n",
    "\n",
    "    with open(report_file_name, 'w') as f:\n",
    "\n",
    "        # using csv.writer method from CSV package\n",
    "        write = csv.writer(f)\n",
    "\n",
    "        write.writerow(fields)\n",
    "        write.writerows(rows)\n",
    "        \n",
    "    rows_new=[]\n",
    "    for i in range(0, len(new_response)):\n",
    "        try:\n",
    "            #items = [new_response[i][\"item\"], new_response[i][\"question\"], new_response[i][\"original question\"], new_response[i][\"DLA_result\"], new_response[i][\"User_input\"], new_response[i][\"User_comment\"]]\n",
    "            items = [new_response[i][\"item\"], new_response[i][\"question\"], new_response[i][\"DLA_result\"], new_response[i][\"User_input\"], new_response[i][\"User_comment\"]]\n",
    "\n",
    "        except:\n",
    "            items = [new_response[i][\"item\"], new_response[i][\"question\"], new_response[i][\"DLA_result\"], new_response[i][\"User_input\"]]\n",
    "        rows_new.append(items)\n",
    "    \n",
    "    fields = ['Item', \"question\", \"Original_question\", \"DLA_result\", \"User_input\", \"User_comment\"] \n",
    "        \n",
    "    with open(notes_file_name, 'w') as f:\n",
    "\n",
    "        # using csv.writer method from CSV package\n",
    "        write = csv.writer(f)\n",
    "\n",
    "        write.writerow(fields)\n",
    "        write.writerows(rows_new)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_q_table(n_states, actions):\n",
    "    table = pd.DataFrame(\n",
    "        np.zeros((n_states, len(actions))),     # q_table initial values\n",
    "        columns=actions,    # actions's name\n",
    "    )\n",
    "#     print(table)    # show table\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_question_q_table(n_states, actions):\n",
    "    question_q_table = build_q_table(n_states, actions)\n",
    "    for i in range(1, n_states):\n",
    "        question_q_table[str(i)] = question_q_table[str(i)].apply(lambda x: x+1)\n",
    "    return question_q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q table for the 20 items\n",
    "def initialize_q_table(ITEM_N_STATES, ITEM_ACTIONS):\n",
    "    item_q_table = build_q_table(ITEM_N_STATES, ITEM_ACTIONS)\n",
    "    for i in range(0, ITEM_N_STATES):\n",
    "        item_q_table[str(i)] = item_q_table[str(i)].apply(lambda x: x+ITEM_IMPORTANCE[i])\n",
    "    return item_q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, q_table, mask, number_states, actions):\n",
    "    # This is how to choose an action\n",
    "    print(\"state in choose action: \", state)\n",
    "    state_action = q_table.iloc[state, :]\n",
    "    #print(state_action)\n",
    "    # update q_table with the mask\n",
    "    for i in range(1, number_states):\n",
    "        q_table[str(i)] = q_table[str(i)].apply(lambda x: x*mask[i])\n",
    "    #print(\"q_table in choose_action():\", q_table)\n",
    "\n",
    "    if (np.random.uniform() > EPSILON) or ((state_action == 0).all()):  # act non-greedy or state-action have no value\n",
    "#         print(\"random: \")\n",
    "        action_name = np.random.choice(actions[1:number_states])\n",
    "    else:   # act greedy\n",
    "        # some actions may have the same value, randomly choose on in these actions\n",
    "#         print(\"max: \")\n",
    "        action_name = np.random.choice(state_action[state_action == np.max(state_action)].index)\n",
    "#    action_name = np.random.choice(state_action[state_action == np.max(state_action)].index) #with no greedy\n",
    "\n",
    "    return action_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_feedback(S, A, openai_res, DLA_terminate, item_mask):\n",
    "    # This is how agent will interact with the environment\n",
    "    if sum(item_mask) == 0: # If all the questions has been asked or the user is really agitated\n",
    "        S_ = 'terminal'\n",
    "        R = 10\n",
    "    elif DLA_terminate == 1:\n",
    "        S_ = 'terminal'\n",
    "        R = 0\n",
    "    else:   # if in the state of asking questions\n",
    "        S_ = int(A)\n",
    "        R = openai_res\n",
    "#     print(S_, R)\n",
    "\n",
    "    return S_, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Google APIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def speech_to_text():\n",
    "#     user_input = \"\"\n",
    "    \n",
    "#     os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"platinum-scout-key.json\"\n",
    "\n",
    "#     # Instantiates a client\n",
    "#     client = speech.SpeechClient()\n",
    "\n",
    "#     # Load media files\n",
    "#     media_file_name_wav = \"demo.wav\"\n",
    "#     with open(media_file_name_wav, 'rb') as f1:\n",
    "#         byte_data_wav = f1.read()\n",
    "#     audio_wav = speech.RecognitionAudio(content = byte_data_wav)\n",
    "\n",
    "#     config_wav = speech.RecognitionConfig(\n",
    "#         sample_rate_hertz=44100,\n",
    "#         enable_automatic_punctuation = True,\n",
    "#         language_code=\"en-US\",\n",
    "#         audio_channel_count = 1\n",
    "#     )\n",
    "\n",
    "#     # Transcribing the recognition audio object\n",
    "#     response_wav = client.recognize(\n",
    "#         config = config_wav,\n",
    "#         audio = audio_wav\n",
    "#     )\n",
    "#     for result in response_wav.results:\n",
    "#         print(\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "#         user_input += result.alternatives[0].transcript\n",
    "#     return user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_to_wav(voice_name: str, text: str):\n",
    "#     language_code = \"-\".join(voice_name.split(\"-\")[:2])\n",
    "#     text_input = tts.SynthesisInput(text=text)\n",
    "#     voice_params = tts.VoiceSelectionParams(\n",
    "#         language_code=language_code, name=voice_name\n",
    "#     )\n",
    "#     audio_config = tts.AudioConfig(audio_encoding=tts.AudioEncoding.LINEAR16)\n",
    "\n",
    "#     client = tts.TextToSpeechClient()\n",
    "#     response = client.synthesize_speech(\n",
    "#         input=text_input, voice=voice_params, audio_config=audio_config\n",
    "#     )\n",
    "\n",
    "#     filename = f\"{language_code}.wav\"\n",
    "#     with open(filename, \"wb\") as out:\n",
    "#         out.write(response.audio_content)\n",
    "#         print(f'Generated speech saved to \"{filename}\"')\n",
    "        \n",
    "#     playsound(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_resp(user_input):\n",
    "\n",
    "    openai.api_key = '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'\n",
    "    res = openai.Completion.create(\n",
    "     # model='davinci:ft-columbia-university-2022-02-28-15-50-17',\n",
    "     model = openai_model,\n",
    "        #'davinci:ft-personal-2022-03-20-19-44-33',\n",
    "     prompt = user_input+\"->\",\n",
    "     max_tokens = 17,)\n",
    "\n",
    "    cmd = res['choices'][0]['text']\n",
    "\n",
    "#     cmd = get_openai_results(user_input)\n",
    "\n",
    "#     print(cmd)\n",
    "#     print(type(cmd))\n",
    "    cmd = cmd.replace(\"->\",\"\")\n",
    "    cmd = cmd.replace(\";\",\",\")\n",
    "    cmd = cmd.replace(\".\",\",\")\n",
    "    \n",
    "    response = cmd.split(\",\")[:2]\n",
    "    try:\n",
    "        category = response[0].replace(\" \",\"\")\n",
    "        score = 99\n",
    "        if category == \"DLA\":\n",
    "            if \"No\" in response[1]:\n",
    "                score = \"No\"\n",
    "            elif \"Yes\" in response[1]:\n",
    "                score = \"Yes\"\n",
    "            elif \"Stop\" in response[1]:\n",
    "                score = \"Stop\"\n",
    "            elif \"Question\" in response[1]:\n",
    "                score = \"Question\"\n",
    "            elif \"Maybe\" in response[1]:\n",
    "                score = 1\n",
    "        else:\n",
    "            try:\n",
    "                if float(response[1]) >=2:\n",
    "                    score = 2        \n",
    "                elif float(response[1]) < 1:\n",
    "                    score = 0\n",
    "                else:\n",
    "                    score = 1   \n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "#     print(score)\n",
    "    if score == 99:\n",
    "        print(\"1\")\n",
    "        try:\n",
    "            all_cmd = cmd.split(\",\")\n",
    "            print(all_cmd)\n",
    "            if \"DLA\" in all_cmd:\n",
    "                category = \"DLA\"\n",
    "                print(\"category\",category)\n",
    "                if \"Stop\" in all_cmd:\n",
    "                    score =\"Stop\"\n",
    "                elif \"Yes\" in all_cmd:\n",
    "                    score =\"Yes\"\n",
    "                elif \"No\" in all_cmd:\n",
    "                    score = \"No\"\n",
    "                else:\n",
    "                    score = 99\n",
    "            else:\n",
    "                category = \"NA\"\n",
    "                score = 99\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    ### Check if there is directly yes or no in the user_input sentence\n",
    "    user_correction = user_input.replace(\".\", \" \")\n",
    "    user_correction = user_correction.replace(\",\", \" \")\n",
    "    user_correction = user_correction.replace(\"?\", \" \")\n",
    "    user_correction = user_correction.split(\" \")\n",
    "    user_correction =[ i.lower() for i in user_correction]\n",
    "    if \"yes\" in user_correction:\n",
    "        category = \"DLA\"\n",
    "        score =\"Yes\"\n",
    "    if \"no\" in user_correction:\n",
    "        category = \"DLA\"\n",
    "        score =\"No\"\n",
    "        \n",
    "    if \"stop\" in user_correction[0]:\n",
    "        category = \"DLA\"\n",
    "        score =\"Stop\"\n",
    "\n",
    "    \n",
    "    return category, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DLA', 'Question')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_openai_resp(\"What about you tell me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer():\n",
    "    while True:\n",
    "        try:\n",
    "            data = pd.read_csv('record.csv')\n",
    "        except:\n",
    "            pass\n",
    "        if data[\"Resp_Lock\"][0] == 0:\n",
    "            user_input = data[\"Resp\"][0] \n",
    "            data[\"Resp_Lock\"][0] = 1\n",
    "            header = [\"Question\", \"Question_Lock\", \"Resp\", \"Resp_Lock\"]\n",
    "            data.to_csv('record.csv', columns = header)\n",
    "            break\n",
    "#     while user_input == \"\":\n",
    "#         text_to_wav('en-US-Standard-A', \"Sorry, I have problem hearing you, please try to speak louder.\")\n",
    "#         detect_and_record()\n",
    "#         user_input = speech_to_text()\n",
    "    user_input.replace(\", and\", \".\")\n",
    "    user_input = user_input.split(\".\")\n",
    "    print(user_input)\n",
    "    DLA_result = []\n",
    "    for i in range(0, len(user_input)):\n",
    "        sentence = user_input[i]\n",
    "        if user_input[i] == \"\":\n",
    "            pass\n",
    "        else:\n",
    "            if user_input[i][0] == \" \":\n",
    "                user_input[i] = user_input[i][1:]\n",
    "            category, score = get_openai_resp(user_input[i])\n",
    "            openai_res = [category, score]\n",
    "            DLA_result.append(openai_res)\n",
    "    print(DLA_result)\n",
    "    return DLA_result, user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_items(DLA_result, user_input):\n",
    "    dla_res = []\n",
    "    user_res = []\n",
    "    for i in range(0, len(DLA_result)):\n",
    "        if DLA_result[i] not in dla_res:\n",
    "            dla_res.append(DLA_result[i])\n",
    "            user_res.append(user_input[i])\n",
    "        else:\n",
    "            index = dla_res.index(DLA_result[i])\n",
    "            user_res[index] += \" \"+user_input[i]\n",
    "    return dla_res, user_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_question(text):\n",
    "    while True:\n",
    "        try:\n",
    "            data = pd.read_csv('record.csv')\n",
    "        except:\n",
    "            pass\n",
    "        if data[\"Question_Lock\"][0] == 0:\n",
    "#                             question = question_lib[str(S)][str(question_A)][\"question\"][0]\n",
    "#                             Question_text = \"Sounds like you did not understand my question. Let me ask it again. \"+question\n",
    "            data[\"Question\"][0] = text\n",
    "            print(text)\n",
    "            data[\"Question_Lock\"][0] = 1\n",
    "            header = [\"Question\", \"Question_Lock\", \"Resp\", \"Resp_Lock\"]\n",
    "            data.to_csv('record.csv', columns = header)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resp_log():\n",
    "    while True:\n",
    "        try:\n",
    "            data = pd.read_csv('record.csv')\n",
    "        except:\n",
    "            pass\n",
    "        if data[\"Resp_Lock\"][0] == 0:\n",
    "            user_input_followup = data[\"Resp\"][0]                            \n",
    "            data[\"Resp_Lock\"][0] = 1\n",
    "            header = [\"Question\", \"Question_Lock\", \"Resp\", \"Resp_Lock\"]\n",
    "            data.to_csv('record.csv', columns = header)\n",
    "            break\n",
    "    return user_input_followup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_result([['DLA_1_height', 0]], \"1\", \"1\", [\"My weight changes a lot\", ''], \"Have you lost or gained a significant amount of weight?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Mobile Version\n",
    "\n",
    "def evaluate_result(DLA_result, S, question_A, user_input, original_question_asked):\n",
    "    global last_question\n",
    "    last_question = \" \"\n",
    "    # have valid answer\n",
    "    therapist_resp = \"\"\n",
    "    try:\n",
    "        if DLA_result[0][1] == \"Question\":\n",
    "            print(\"evaluate question check\")\n",
    "            question = question_lib[str(S)][str(question_A)][\"question\"][0]\n",
    "            Question_text = \"Sounds like you did not understand my question. Let me ask it again. \"+question\n",
    "            log_question(Question_text)\n",
    "#             while True:\n",
    "#                 try:\n",
    "#                     data = pd.read_csv('record.csv')\n",
    "#                 except:\n",
    "#                     pass\n",
    "#                 if data[\"Question_Lock\"][0] == 0:\n",
    "#                     question = question_lib[str(S)][str(question_A)][\"question\"][0]\n",
    "#                     Question_text = \"Sounds like you did not understand my question. Let me ask it again. \"+question\n",
    "#                     data[\"Question\"][0] = Question_text \n",
    "#                     print(Question_text)\n",
    "#                     data[\"Question_Lock\"][0] = 1\n",
    "#                     header = [\"Question\", \"Question_Lock\", \"Resp\", \"Resp_Lock\"]\n",
    "#                     data.to_csv('record.csv', columns = header)\n",
    "#                     break\n",
    "            DLA_result, user_input = get_answer()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    DLA_result, user_input = remove_duplicate_items(DLA_result, user_input)\n",
    "    valid = 0\n",
    "    DLA_terminate = 0\n",
    "    print(\"check\")\n",
    "    \n",
    "    try:\n",
    "        print(\"3\")\n",
    "        if type(DLA_result[0][1]) == str: # Check if there is direct yes or no ansewer to the question\n",
    "            print(\"1 + There is direct yes/no/stop to the question\")\n",
    "            if DLA_result[0][1] == \"Stop\":\n",
    "                DLA_terminate = 1             \n",
    "                \n",
    "            else:\n",
    "                print(\"2\")\n",
    "                score = question_lib[str(S)][str(question_A)][DLA_result[0][1]]\n",
    "                question_lib[str(S)][str(question_A)][\"score\"].append(score)\n",
    "                valid = 1\n",
    "                if score > 1:  \n",
    "                    print(\"If score > 1 for direct yes/no/stop\")\n",
    "                    text = question_lib[str(S)][str(question_A)][\"question\"][0]\n",
    "                    if DLA_result[0][1] == \"Yes\":\n",
    "                        text = generate_change_positive(text)\n",
    "                    else:\n",
    "                        text = generate_change_negative(text)\n",
    "                # Repeat the question\n",
    "                    text_temp = generate_synonymous_sentences(\" Can you tell me more about it?\")\n",
    "                    question_text = \"It seems that \"+text+\" \"+text_temp\n",
    "                    \n",
    "                    log_question(question_text)\n",
    "                    print(\"4\")\n",
    "                    \n",
    "                    user_input_followup = get_resp_log()\n",
    "                    \n",
    "                    print(\"5\", user_input_followup)\n",
    "                                \n",
    "                    therapist_resp = generate_therapist_chat(text+\" \"+user_input_followup)\n",
    "                    #log_question(therapist_resp)\n",
    "                    print(\"therapist_resp in evaluate Y/N\", therapist_resp)\n",
    "                    print(\"6\")\n",
    "                    last_question = therapist_resp\n",
    "        \n",
    "                    original_resp = \"original_resp: \" + user_input[0]\n",
    "                    followup_resp = \"followup_resp: \" + user_input_followup\n",
    "                    #therapist_resp =  \"therapist_resp: \" + therapist_resp\n",
    "                    original_question_asked_record = \"original_question: \"+original_question_asked\n",
    "                    note_resp = [original_question_asked_record, original_resp, followup_resp, \"therapist_resp: \" + therapist_resp]\n",
    "                    question_lib[str(S)][str(question_A)][\"notes\"].append(note_resp)\n",
    "                else:\n",
    "                    original_resp = \"original_resp: \" + user_input[0]\n",
    "                    original_question_asked_record = \"original_question: \"+original_question_asked\n",
    "                    note_resp = [original_question_asked_record, original_resp]\n",
    "                    question_lib[str(S)][str(question_A)][\"notes\"].append(note_resp)\n",
    "        question_label = question_lib[str(S)][str(question_A)][\"label\"]\n",
    "        error_count = 0\n",
    "        rephrase_count = 0\n",
    "        for i in range(0, len(DLA_result)): \n",
    "            # check if the user have valid answer for the question that been asked\n",
    "            print(\"Evaluate DLA: \", DLA_result[i])\n",
    "\n",
    "            if type(DLA_result[i][1]) == str: # Check if there is a stop indication to the question\n",
    "                if DLA_result[i][1] == \"Stop\":\n",
    "                    DLA_terminate = 1\n",
    "                    valid = 1\n",
    "                return valid, DLA_terminate, last_question\n",
    "            else:            \n",
    "                label = DLA_result[i][0]\n",
    "                print(\"label\", label)\n",
    "                if type(DLA_result[i][1]) == int and DLA_result[i][1] != 99:\n",
    "                    if DLA_result[i][0].lower() == question_label.lower():\n",
    "                        valid = 1\n",
    "                    print(valid)\n",
    "                    score = DLA_result[i][1]\n",
    "                    print(\"Score: \", score)\n",
    "                    if score > 1:\n",
    "                        text = user_input[i]\n",
    "                        text = generate_change(text)\n",
    "                    # Repeat the question\n",
    "                        question_text = \"You mentioned that \"+text+\" Can you tell me more?\"\n",
    "                        \n",
    "#                         text_to_wav(speaker, question_text)\n",
    "#                         print(question_text)\n",
    "#                         detect_and_record()\n",
    "                        \n",
    "                        \n",
    "                        log_question(question_text)\n",
    "                        print(\"7\")\n",
    "\n",
    "#                         user_input_followup = speech_to_text()\n",
    "                        user_input_followup = get_resp_log()\n",
    "\n",
    "                        print(\"8\", user_input_followup)\n",
    "\n",
    "                        therapist_resp = generate_therapist_chat(text+\" \"+user_input_followup)\n",
    "                        print(\"therapist_resp in evaluate\", therapist_resp)\n",
    "                        #log_question(therapist_resp)\n",
    "                        print(\"9\")\n",
    "                        \n",
    "#                         therapist_resp = generate_therapist_chat(text+\" \"+user_input_followup)\n",
    "#                         text_to_wav(speaker, therapist_resp)\n",
    "\n",
    "                    try:\n",
    "                        print(\"check1\")\n",
    "                        item_number = DLA_result[i][0].split(\"_\")[1]\n",
    "                        print(item_number)\n",
    "                        if int(item_number) == 21:\n",
    "                            item_number = 19\n",
    "                        print(len(question_lib[str(item_number)]))\n",
    "                        if len(question_lib[str(item_number)]) == 1:\n",
    "                            print(\"Only one question in this item.\")\n",
    "    #                         print(question_lib[str(item_number)][\"1\"][\"label\"].lower(), label.lower())\n",
    "                            if question_lib[str(item_number)][\"1\"][\"label\"].lower() == label.lower():\n",
    "                                question_number = 1\n",
    "                            \n",
    "                        else: \n",
    "                            for ind in range(1, len(question_lib[str(item_number)])+1):\n",
    "                                if question_lib[str(item_number)][str(ind)][\"label\"].lower() == label.lower():\n",
    "                                    question_number = ind\n",
    "                       \n",
    "                        try:\n",
    "                            print(\"item_number, question_number, valid:\", item_number, question_number, valid)\n",
    "                            question_lib[str(item_number)][str(question_number)][\"score\"].append(score)\n",
    "                            if score>1:\n",
    "                                original_resp = \"original_resp: \" + user_input[i]\n",
    "                                followup_resp = \"followup_resp: \" + user_input_followup\n",
    "#                                 therapist_resp =  \"therapist_resp: \" + therapist_resp\n",
    "                                original_question_asked_record = \"original_question: \"+original_question_asked\n",
    "                                note_resp = [original_question_asked_record, original_resp, followup_resp, \"therapist_resp: \" + therapist_resp]\n",
    "                                question_lib[str(item_number)][str(question_number)][\"notes\"].append(note_resp)\n",
    "                            else:\n",
    "                                original_resp = \"original_resp: \" + user_input[i]\n",
    "                                original_question_asked_record = \"original_question: \"+original_question_asked\n",
    "                                note_resp = [original_question_asked_record, original_resp, original_question_asked_record]\n",
    "                                question_lib[str(item_number)][str(question_number)][\"notes\"].append(note_resp)\n",
    "                                \n",
    "                                if label == \"DLA_21_sports\" and score == 0:\n",
    "                                    question_lib[str(11)][str(1)][\"notes\"].append(note_resp) ## if people do sports, that means they have hobbies\n",
    "                                    question_lib[str(11)][str(1)][\"score\"].append(score)\n",
    "                                    if int(S) == 11 and int(question_A) == 1:\n",
    "                                        valid = 1\n",
    "                                    \n",
    "                        except:\n",
    "                            print(\"Have problem processing the response.\")\n",
    "                            print(S, question_A, DLA_result[i], user_input[i])\n",
    "                            correction = {\"item\": S, \"question\": question_A, \"DLA_result\":DLA_result[i], \"User_input\":user_input[i]}\n",
    "    #                         new_response.append({\"item\": S, \"question\": question_A, \"DLA_result\":DLA_result[i], \"User_input\":user_input[i]})\n",
    "                            if len(DLA_result) == 1:\n",
    "                                question_text = \"Sorry, our system currently cannot process your response in a correct way. We need your help to improve the system. \"\n",
    "                                question_text += \"You are trying to answer: \"+ original_question_asked+\". And your response is: \"+user_input[i]+\". Is that right? \"\n",
    "                                question_text += \"If that's right, please say YES. If we didn't get it right, please say No.\"\n",
    "                                print(\"10\", question_text)\n",
    "                        \n",
    "                                log_question(question_text)\n",
    "                                print(\"11\")\n",
    "\n",
    "                                user_correction = get_resp_log()\n",
    "                                print(\"12\", user_correction)\n",
    "                                \n",
    "\n",
    "                            else:\n",
    "                                if error_count == 0:\n",
    "                                    question_text = \"Sorry, our system currently cannot process part of your response in a correct way. We need your help to improve the system. \"\n",
    "                                    question_text += \"You are trying to answer: \"+ original_question_asked+\"that the system asked. And a part of your response is: \"+user_input[i]+\". Is that right? \"\n",
    "                                    question_text += \"If that's right, please say YES. If we didn't get it right, please say No.\"\n",
    "                                    print(\"10\", question_text)\n",
    "                        \n",
    "                                    log_question(question_text)\n",
    "                                    print(\"11\")\n",
    "\n",
    "                                    error_count += 1\n",
    "                                else:\n",
    "                                    question_text = \"Sorry again, our system currently cannot process another part of your response in a correct way. We need your help again.\"\n",
    "                                    question_text += \"You are trying to answer: \"+ original_question_asked+\"that the system asked. And a part of your response is: \"+user_input[i]+\". Is that right? \"\n",
    "                                    question_text += \"If that's right, please say YES. If we didn't get it right, please say No.\"\n",
    "                                    print(\"12\", question_text)\n",
    "                        \n",
    "                                    log_question(question_text)\n",
    "                                    print(\"13\")\n",
    "                                \n",
    "                                    error_count += 1\n",
    "\n",
    "                                user_correction = get_resp_log()\n",
    "                                print(\"15\", user_correction)\n",
    "                                \n",
    "                            user_correction = user_correction.replace(\".\", \" \")\n",
    "                            user_correction = user_correction.replace(\",\", \" \")\n",
    "                            user_correction = user_correction.replace(\"?\", \" \")\n",
    "                            user_correction = user_correction.split(\" \")\n",
    "                            user_correction =[ i.lower() for i in user_correction]\n",
    "                            if \"no\" in user_correction:\n",
    "                                question_text = \"It seems like we did not get it right. Please tell us what is not right for you.\"\n",
    "                                log_question(question_text)\n",
    "                                user_correction = get_resp_log()\n",
    "                                correction = {\"item\": S, \"question\": question_A, \"original question\": original_question_asked, \"DLA_result\":DLA_result[i], \"User_input\":user_input[i], \"User_comment\": user_correction}\n",
    "                            elif \"yes\" in user_correction:\n",
    "                                print(\"in evaluate: check if need to rephrase the answer.\")\n",
    "                                if rephrase_count == 0:\n",
    "                                    print(\"Please rephrase.\")\n",
    "                                    question_text = \"Could you please rephrase your answer to our question: \"+original_question_asked\n",
    "                                    log_question(question_text)\n",
    "                                    user_correction = get_resp_log()\n",
    "                                    correction = {\"item\": S, \"question\": question_A, \"original question\": original_question_asked, \"DLA_result\":DLA_result[i], \"User_input\":user_input[i], \"User_comment\": user_correction}\n",
    "                                    rephrase_count += 1\n",
    "                                else:\n",
    "                                    pass\n",
    "                                    \n",
    "                            therapist_resp = \"Thank you for your feedback. We will improve our system and provide a better user experience for you.\"\n",
    "                            print(\"16\", therapist_resp)\n",
    "                            #log_question(question_text)\n",
    "                            new_response.append(correction)\n",
    "                            valid = 1\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    last_question = therapist_resp\n",
    "    print('last_question in evaluate_result: ', last_question)\n",
    "    \n",
    "    return valid, DLA_terminate, last_question\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize all question q tables\n",
    "def initialize_question_table():\n",
    "    all_question_q_table = {}\n",
    "    ITEM_ACTIONS = ['{0}'.format(element) for element in np.arange(0, ITEM_N_STATES)]   \n",
    "    for i in range(0, ITEM_N_STATES):\n",
    "        if NUMBER_QUESTIONS[i]>1:\n",
    "            question_actions = ['{0}'.format(element) for element in np.arange(NUMBER_QUESTIONS[i]+1)]\n",
    "            question_q_table = initialize_question_q_table(NUMBER_QUESTIONS[i]+1, question_actions)\n",
    "            #print(question_q_table)\n",
    "            all_question_q_table[i] = question_q_table\n",
    "    return all_question_q_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_question_mask():\n",
    "    all_question_mask = {}\n",
    "    for i in range(0, ITEM_N_STATES):\n",
    "        if NUMBER_QUESTIONS[i]>1:\n",
    "            all_question_mask[i] = [0]+[1] * NUMBER_QUESTIONS[i]\n",
    "    return all_question_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(S, all_question_mask): # the sequence to ask question in each item\n",
    "    global last_question\n",
    "    print(\"Item number: \", S)\n",
    "#     speaker = US_speakers[np.random.randint(20)]\n",
    "    question_S = 0\n",
    "    question_A_order = []\n",
    "    question_reward = []\n",
    "    DLA_terminate = 0\n",
    "    if NUMBER_QUESTIONS[S]>1: # if there's more than one question\n",
    "        question_actions = ['{0}'.format(element) for element in np.arange(NUMBER_QUESTIONS[S]+1)]\n",
    "        question_q_table = all_question_q_table[S].copy()\n",
    "        question_mask = all_question_mask[S]\n",
    "        new_question_q_table = question_q_table.copy()\n",
    "#         print(\"question_q_table\", question_q_table)\n",
    "#         print(\"new_question_q_table\", new_question_q_table)\n",
    "        is_terminated = False\n",
    "        number_of_states = NUMBER_QUESTIONS[S]+1\n",
    "        while not is_terminated:\n",
    "            print(\"*\"*99)\n",
    "            question_A = choose_action(question_S, question_q_table, question_mask, number_of_states, question_actions)\n",
    "            print(\"Question Action\", question_A)\n",
    "            question_mask[int(question_A)] = 0\n",
    "            print(\"question_mask\", question_mask)\n",
    "            print(\"score in log\", question_lib[str(S)][str(question_A)][\"score\"])\n",
    "            #### interface to OpenAI model & Alexa here:\n",
    "            #############################################\n",
    "            \n",
    "            ## Only ask the question and get the answer from the user when the item is not been answered before.\n",
    "            if len(question_lib[str(S)][str(question_A)][\"score\"]) == 0:\n",
    "                number_of_questions = len(question_lib[str(S)][str(question_A)][\"question\"])\n",
    "                choice_of_question = np.random.randint(number_of_questions)\n",
    "                question_text = question_lib[str(S)][str(question_A)][\"question\"][choice_of_question]\n",
    "                question_label = question_lib[str(S)][str(question_A)][\"label\"]\n",
    "                #generate synonymous sentence under certain probability\n",
    "                if (np.random.uniform() > 0.95):\n",
    "                    question_text = generate_synonymous_sentences(question_text)\n",
    "\n",
    "                print(question_text)\n",
    "                question_text_ask = last_question +\"  \"+ question_text\n",
    "                print(last_question, question_text)\n",
    "                # Either ask question from ALEXA or from a standalone speaker\n",
    "                #text_to_wav(speaker, question_text)\n",
    "                \n",
    "                log_question(question_text_ask)\n",
    "                \n",
    "\n",
    "                # Get the response from the user:\n",
    "                DLA_result, user_input = get_answer()\n",
    "                print(DLA_result, user_input)\n",
    "                valid, DLA_terminate, last_question = evaluate_result(DLA_result, S, question_A, user_input, question_text)\n",
    "                print(last_question)\n",
    "                \n",
    "                print(\"DLA_result:\", DLA_result)\n",
    "                print(\"valid:\", valid)\n",
    "                print(\"DLA_terminate:\", DLA_terminate)\n",
    "\n",
    "                #ask until valid\n",
    "                if valid == 0 and DLA_terminate == 0:\n",
    "                    valid_loop = 0\n",
    "                    while valid_loop < 1:\n",
    "                        question_to_ask = last_question+\"Sorry. Do you mind rephrasing your answer in a different way. Please make sure you answer the question I ask. \"\n",
    "                        if (np.random.uniform() > 0.5):\n",
    "                            question_to_ask += \"And try to answer my question in a complete sentence and in a concise and deterministic way if you can.\"\n",
    "                        log_question(question_text_ask)\n",
    "                        DLA_result, user_input = get_answer()\n",
    "                        valid_loop, DLA_terminate, last_question = evaluate_result(DLA_result, S, question_A, user_input,question_text)\n",
    "                print(\"last question\", last_question)\n",
    "            else:\n",
    "                print(\"Already answered, get reward from history\")\n",
    "\n",
    "            all_score = question_lib[str(S)][str(question_A)][\"score\"]            \n",
    "            question_openai_res = np.mean(all_score)\n",
    "            #DLA_terminate = 0\n",
    "            \n",
    "            \n",
    "            ###\n",
    "            question_S_, question_R = get_env_feedback(question_S, question_A, question_openai_res, DLA_terminate, question_mask)  # take action & get next state and reward\n",
    "            question_A_order.append(question_A)\n",
    "            question_reward.append(question_R)\n",
    "            q_predict = question_q_table.loc[question_S, question_A]\n",
    "            if question_S_ != 'terminal':\n",
    "                q_target = question_R + GAMMA * question_q_table.iloc[question_S_, :].max()   # next state is not terminal\n",
    "            else:\n",
    "                q_target = question_R     # next state is terminal\n",
    "                is_terminated = True    # terminate this episode\n",
    "            print(\"q_target\", q_target, \"q_predict\", q_predict)\n",
    "            new_question_q_table.loc[question_S, question_A] += ALPHA * (q_target - q_predict)  # update\n",
    "            print(\"new_question_q_table after update\", new_question_q_table)\n",
    "            question_S = question_S_  # move to next state  \n",
    "            if DLA_terminate == 1:\n",
    "                is_terminated = True\n",
    "\n",
    "        question_q_table = new_question_q_table.copy()\n",
    "        print(\"question_q_table after update\", question_q_table)\n",
    "        all_question_q_table[S] = question_q_table.copy()\n",
    "        print(\"all_question_q_table[S]\", all_question_q_table[S])\n",
    "        all_question_mask[S] = question_mask\n",
    "        print(\"_\"*99)\n",
    "    else:\n",
    "        question_A = \"1\" ## There will be only 1 question\n",
    "        \n",
    "        ## Only ask the question and get the answer from the user when the item is not been answered before.\n",
    "        if len(question_lib[str(S)][str(question_A)][\"score\"]) == 0:\n",
    "            number_of_questions = len(question_lib[str(S)][str(question_A)][\"question\"])\n",
    "            choice_of_question = np.random.randint(number_of_questions)\n",
    "            question_text = question_lib[str(S)][str(question_A)][\"question\"][choice_of_question]\n",
    "            question_label = question_lib[str(S)][str(question_A)][\"label\"]\n",
    "            #generate synonymous sentence under certain probability\n",
    "            if (np.random.uniform() > 0.95):\n",
    "                question_text = generate_synonymous_sentences(question_text)\n",
    "\n",
    "            print(question_text)\n",
    "\n",
    "#             # Either ask question from ALEXA or from a standalone speaker\n",
    "#             text_to_wav(speaker, question_text)\n",
    "\n",
    "#             # Get the response from the user:\n",
    "#             DLA_result, user_input = get_answer()\n",
    "#             valid, DLA_terminate = evaluate_result(DLA_result, S, question_A, user_input, question_text)\n",
    "#             print(DLA_result)\n",
    "#             print(valid)\n",
    "#             print(\"DLA_terminate:\", DLA_terminate)\n",
    "            \n",
    "\n",
    "            question_text_ask = last_question + \"  \"+question_text\n",
    "\n",
    "            # Either ask question from ALEXA or from a standalone speaker\n",
    "            #text_to_wav(speaker, question_text)\n",
    "            log_question(question_text_ask)\n",
    "\n",
    "            # Get the response from the user:\n",
    "            DLA_result, user_input = get_answer()\n",
    "            valid, DLA_terminate, last_question = evaluate_result(DLA_result, S, question_A, user_input, question_text)\n",
    " \n",
    "            print(\"DLA_result:\", DLA_result)\n",
    "            print(\"valid:\", valid)\n",
    "            print(\"DLA_terminate:\", DLA_terminate)\n",
    "\n",
    "            #ask until valid\n",
    "            if valid == 0 and DLA_terminate == 0:\n",
    "                valid_loop = 0\n",
    "                while valid_loop < 1:\n",
    "                    question_to_ask = last_question+\"Sorry. Do you mind rephrasing your answer in a different way. Please make sure you answer the question I ask. \"\n",
    "                    if (np.random.uniform() > 0.5):\n",
    "                        question_to_ask += \"And try to answer my question in a complete sentence and in a concise and deterministic way if you can.\"\n",
    "                    log_question(question_text_ask)\n",
    "                    DLA_result, user_input = get_answer()\n",
    "                    valid_loop, DLA_terminate, last_question = evaluate_result(DLA_result, S, question_A, user_input,question_text)\n",
    "            print(\"last question\", last_question)\n",
    "            \n",
    "\n",
    "#             #ask until valid\n",
    "#             if valid == 0 and DLA_terminate == 0:\n",
    "#                 valid_loop = 0\n",
    "#                 while valid_loop < 1:\n",
    "#                     text_to_wav(speaker, \"Sorry. Do you mind rephrasing your answer in a different way. Please make sure you answer the question I ask.\")\n",
    "#                     if (np.random.uniform() > 0.5):\n",
    "#                         text_to_wav(speaker, \"And try to answer my question in a complete sentence if you can.\")\n",
    "#                     text_to_wav(speaker, question_text)\n",
    "#                     DLA_result, user_input = get_answer()\n",
    "#                     valid_loop, DLA_terminate = evaluate_result(DLA_result, S, question_A, user_input, question_text)\n",
    "        else:\n",
    "            print(\"Already answered, get reward from history\")\n",
    "\n",
    "        all_score = question_lib[str(S)][str(question_A)][\"score\"]            \n",
    "        question_openai_res = np.mean(all_score)\n",
    "#         ### interface to OpenAI model & Alexa here:\n",
    "#         question_text = question_lib[str(S)][\"1\"][\"question\"][0]\n",
    "            \n",
    "#         #generate synonymous sentence under certain probability\n",
    "#         if (np.random.uniform() > 0.5):\n",
    "#             question_text = generate_synonymous_sentences(question_text)\n",
    "\n",
    "#         print(question_text)\n",
    "\n",
    "#         # Either ask question from ALEXA or from a standalone speaker\n",
    "#         text_to_wav(\"en-US-Wavenet-F\", question_text)\n",
    "        \n",
    "#         # Get the response from the user:\n",
    "#         DLA_result = get_answer()\n",
    "#         print(DLA_result)\n",
    "        \n",
    "#         question_openai_res = np.random.randint(5)\n",
    "# #         DLA_terminate = 0\n",
    "        ###\n",
    "        question_reward.append(question_openai_res)\n",
    "    print(\"question_reward: \", question_reward)\n",
    "    openai_res = sum(question_reward) \n",
    "    print(\"DLA_terminate\", DLA_terminate)\n",
    "    \n",
    "    return openai_res, DLA_terminate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBT AND MI functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_MI_CBT(save_filename):\n",
    "    #global question_lib_result\n",
    "    f = open(save_filename)\n",
    "    question_lib_result = json.load(f)\n",
    "    issue_dimension = []\n",
    "    good_dimension = []\n",
    "    for i in range(1, len(question_lib_result)+1):\n",
    "        for ind in range(1, len(question_lib_result[str(i)])+1):\n",
    "            if sum(question_lib_result[str(i)][str(ind)][\"score\"]) > 1:\n",
    "                name = question_lib_result[str(i)][str(ind)][\"name\"]\n",
    "                issue_dimension.append([i, ind, name])\n",
    "\n",
    "            elif sum(question_lib_result[str(i)][str(ind)][\"score\"]) < 1:\n",
    "                name = question_lib_result[str(i)][str(ind)][\"name\"]\n",
    "                good_dimension.append([i, ind, name])\n",
    "                \n",
    "    return issue_dimension, good_dimension\n",
    "\n",
    "def get_dimension_to_work(save_filename, issue_dimension, issue_dimension_number):\n",
    "    #global question_lib_result\n",
    "    f = open(save_filename)\n",
    "    question_lib_result = json.load(f)\n",
    "    for i in range(0, len(issue_dimension)):\n",
    "        stop = issue_dimension[i][2].index(\":\") \n",
    "        dimension_name_number = issue_dimension[i][2][0:stop]\n",
    "        if \"Dimension \"+str(issue_dimension_number) == dimension_name_number:\n",
    "            item_number = issue_dimension[i][0]\n",
    "            question_number = issue_dimension[i][1]\n",
    "            dimension_name = issue_dimension[i][2]\n",
    "            \n",
    "    summary_original_response = []\n",
    "    summary_followup_response = []\n",
    "\n",
    "    for i in range(len(question_lib_result[str(item_number)][str(question_number)][\"notes\"])):\n",
    "        for ind in range(len(question_lib_result[str(item_number)][str(question_number)][\"notes\"][i])):\n",
    "            if \"original_resp\" in question_lib_result[str(item_number)][str(question_number)][\"notes\"][i][ind]:\n",
    "                temp = question_lib_result[str(item_number)][str(question_number)][\"notes\"][i][ind].index(\":\")\n",
    "                resp = question_lib_result[str(item_number)][str(question_number)][\"notes\"][i][ind][temp+2:]\n",
    "                summary_original_response.append(resp)\n",
    "\n",
    "            if \"followup_resp\" in question_lib_result[str(item_number)][str(question_number)][\"notes\"][i][ind]:\n",
    "                temp = question_lib_result[str(item_number)][str(question_number)][\"notes\"][i][ind].index(\":\")\n",
    "                resp = question_lib_result[str(item_number)][str(question_number)][\"notes\"][i][ind][temp+2:]\n",
    "                summary_followup_response.append(resp)\n",
    "    return item_number, question_number, summary_original_response, summary_followup_response\n",
    "\n",
    "def proceed_MI_CBT(save_filename):\n",
    "    f = open(save_filename)\n",
    "    question_lib_result = json.load(f)\n",
    "    issue_dimension, good_dimension = prepare_for_MI_CBT(save_filename)\n",
    "    ## if no issue with the subject:\n",
    "    category = \"category\"\n",
    "    score = \"score\"\n",
    "    if len(issue_dimension)==0:\n",
    "        Q5 = \"It seems like you are doing pretty well. You work well in dimensions including: \" \n",
    "        sample_good_dimension = random.sample(range(len(good_dimension)), 3)\n",
    "        Q5 += good_dimension[sample_good_dimension[0]][2] + \", \"+good_dimension[sample_good_dimension[1]][2]+\", and \"+ good_dimension[sample_good_dimension[2]][2]\n",
    "        Q5 += \". Please reach out to your primary care or your therapist if you have further problems or emergencies.\"\n",
    "        Q5 += \"Goodbye. We will followup later. 886\"\n",
    "        print(\"Q5:\", Q5)\n",
    "        log_question(Q5)\n",
    "    \n",
    "    else:\n",
    "        #Q1:#####################################################\n",
    "        Q1 = \"Thank you for answering all the questions. \"\n",
    "        if (np.random.uniform() > 0.95):\n",
    "            Q1 = generate_synonymous_sentences(Q1)\n",
    "        Q1 += \"According to your previous responses, you have issues in \"\n",
    "        for i in range(0, len(issue_dimension)):\n",
    "            Q1 += issue_dimension[i][2]+\", \"\n",
    "        Q1 += \"Which dimension do you want to work on today? Please speak out the dimension number, for example, \"\n",
    "        stop = issue_dimension[i][2].index(\":\") \n",
    "        Q1 += issue_dimension[0][2][stop-2:stop-1] + \".\"\n",
    "        print(\"Q1:\", Q1)\n",
    "        \n",
    "        log_question(Q1)\n",
    "        \n",
    "        user_dimension = str(get_resp_log())\n",
    "        user_dimension = user_dimension.replace(\".0\",\"\").replace(\".\", \"\")\n",
    "        \n",
    "        print(\"user_dimension1:\", user_dimension)\n",
    "        try:\n",
    "            category, score = get_openai_resp(user_dimension)\n",
    "        except:\n",
    "            pass\n",
    "        Q2 = \" \"\n",
    "        if score == \"Question\":\n",
    "            print(\"check\")\n",
    "            Q1 = \"It seems like you don't understand me well. Let me repeat my question. According to your previous responses, you have issues in \"\n",
    "            for i in range(0, len(issue_dimension)):\n",
    "                Q1 += issue_dimension[i][2]+\", \"\n",
    "            Q1 += \"Which dimension do you want to work on today? Please speak out the dimesion number, for example, \"\n",
    "            stop = issue_dimension[i][2].index(\":\") \n",
    "            Q1 += issue_dimension[0][2][stop-2:stop-1] + \".\"\n",
    "            log_question(Q1)\n",
    "            user_dimension = str(get_resp_log())\n",
    "            print(\"user_dimension2:\", user_dimension)\n",
    "            user_dimension = user_dimension.replace(\".0\",\"\").replace(\".\", \"\")\n",
    "            category, score = get_openai_resp(user_dimension)\n",
    "            if score == \"Question\":\n",
    "                user_dimension = random.choice(issue_dimension)[2]\n",
    "                stop = random.choice(issue_dimension)[2]\n",
    "                user_dimension = user_dimension.replace(\":\", \" \").replace(\"n\", \" \")\n",
    "                user_dimension = int(user_dimension[stop-2:stop+1])\n",
    "                print(\"user_dimension2:\", user_dimension)\n",
    "                Q2 = \"I pick a dimension to work on today.\"\n",
    "        try:\n",
    "            issue_dimension_number = w2n.word_to_num(user_dimension)\n",
    "            issue_dimension_number = int(user_dimension)\n",
    "        except:\n",
    "            try:\n",
    "                issue_dimension_number = w2n.word_to_num(user_dimension)\n",
    "            except:\n",
    "                print(\"fail to get issue_dimension_number\")\n",
    "                user_dimension = random.choice(issue_dimension)[2]\n",
    "                stop = random.choice(issue_dimension)[2].index(\":\")\n",
    "                user_dimension = user_dimension.replace(\":\", \" \").replace(\"n\", \" \")\n",
    "                issue_dimension_number = int(user_dimension[stop-2:stop+1])\n",
    "                Q2 = \"I have problem getting the dimension you want to work on. So I pick a dimension to work on today. \"\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in range(0, len(issue_dimension)):\n",
    "            dim = \"Dimension \"+str(issue_dimension_number)\n",
    "            if dim in issue_dimension[i][2]:\n",
    "                cnt+=1\n",
    "        if cnt == 0:\n",
    "            user_dimension = random.choice(issue_dimension)[2]\n",
    "            stop = random.choice(issue_dimension)[2].index(\":\")\n",
    "            user_dimension = user_dimension.replace(\":\", \" \").replace(\"n\", \" \")\n",
    "            issue_dimension_number = int(user_dimension[stop-2:stop+1])\n",
    "            Q2 = \"Looks like you are doing OK with the dimension you chose. So I pick an issue dimension to work on today. \"\n",
    "        #Q2:#####################################################\n",
    "        item_number, question_number, summary_original_response, summary_followup_response = get_dimension_to_work(save_filename, issue_dimension, issue_dimension_number)\n",
    "        \n",
    "        Q2 += \"Let's work on Dimension \" + str(issue_dimension_number)+\". From my record, you mentioned: \"\n",
    "            \n",
    "        for i in range(0, len(summary_original_response)):\n",
    "            Q2 += summary_original_response[i]+\" and \"\n",
    "\n",
    "        for i in range(0, len(summary_followup_response)):\n",
    "            Q2 += summary_followup_response[i]+\" and \"\n",
    "\n",
    "        Q2 = Q2[:-5]\n",
    "        Q2 += \" Can you try to identify any unhelpful thoughts you have that contribute to this situation?\"\n",
    "        print(\"Q2:\", Q2)\n",
    "        log_question(Q2)        \n",
    "        user_thought = str(get_resp_log())\n",
    "        print(\"user_thought:\", user_thought)\n",
    "        category, score = get_openai_resp(user_thought)\n",
    "        \n",
    "        if score == \"Question\":\n",
    "            Q2 = \"It seems like you can not get my question. Let me repeat my question. We are working on Dimension \" + str(issue_dimension_number)+\". From my record, you mentioned: \"\n",
    "            \n",
    "            for i in range(0, len(summary_original_response)):\n",
    "                Q2 += summary_original_response[i]+\" and \"\n",
    "\n",
    "            for i in range(0, len(summary_followup_response)):\n",
    "                Q2 += summary_followup_response[i]+\" and \"\n",
    "\n",
    "            Q2 = Q2[:-5]\n",
    "            Q2 += \" Can you try to identify any unhelpful thoughts you have that contribute to this situation?\"\n",
    "            print(\"Q2:\", Q2)\n",
    "            log_question(Q2)        \n",
    "            user_thought = get_resp_log()\n",
    "       \n",
    "        ##### Q3\n",
    "        \n",
    "        Q3 = \"Can you challenge your thought?\"\n",
    "        log_question(Q3)   \n",
    "        print(\"Q3:\", Q3)\n",
    "        user_challenge = str(get_resp_log())\n",
    "        print(\"user_challenge:\", user_challenge)\n",
    "        ####### Q4\n",
    "        \n",
    "        rephrase_challenge = generate_change(user_challenge)\n",
    "        Q4 = \"You mentioned that: \"+rephrase_challenge + \" to challenge your thought. Now, what is another way of thinking about this situation?\"\n",
    "        print(\"Q4:\", Q4)\n",
    "        log_question(Q4)\n",
    "        user_new_way = get_resp_log()\n",
    "        print(\"user_new_way:\", user_new_way)\n",
    "        \n",
    "        ####### Q5\n",
    "        \n",
    "        Q5 = \"Congratulation, you figure out a way for yourself. You also work well in dimensions including: \" \n",
    "        sample_good_dimension = random.sample(range(len(good_dimension)), 3)\n",
    "        Q5 += good_dimension[sample_good_dimension[0]][2] + \", \"+good_dimension[sample_good_dimension[1]][2]+\", and \"+ good_dimension[sample_good_dimension[2]][2]\n",
    "        Q5 += \". Please reach out to your primary care or your therapist if you have further problems or emergencies.\"\n",
    "        Q5 += \"Goodbye. We will followup later. 886\"\n",
    "        print(\"Q5:\", Q5)\n",
    "        log_question(Q5)\n",
    "        \n",
    "        CBT_notes = ['CBT_Dimension: '+str(user_dimension), \"CBT_unhelpful_thought: \"+str(user_thought), \"CBT_challenge: \"+str(user_challenge),\n",
    "                    \"CBT_new_way:\"+str(user_new_way)]\n",
    "        \n",
    "        f = open(save_filename)\n",
    "        question_lib_result = json.load(f)\n",
    "        question_lib_result[str(item_number)][str(question_number)][\"notes\"].append(CBT_notes)\n",
    "        \n",
    "        with open(save_filename, 'w') as f:\n",
    "            json.dump(question_lib_result, f)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_question_q_table():\n",
    "    elements = [1, 3, 4, 5, 9, 10, 11, 14, 15, 17]\n",
    "    for i in range(len(all_question_q_table)):\n",
    "        filename = str(elements[i])+\".pkl\"\n",
    "        all_question_q_table[elements[i]].to_pickle(filename)\n",
    "\n",
    "\n",
    "\n",
    "def load_all_question_q_table():\n",
    "    test = {}\n",
    "    elements = [1, 3, 4, 5, 9, 10, 11, 14, 15, 17]\n",
    "    for i in range(10):\n",
    "        filename = str(elements[i])+\".pkl\"\n",
    "        test[elements[i]] = pd.read_pickle(filename)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_subject = int(input(\"New Subject? Yes:1, No:0\"))\n",
    "# if new_subject:\n",
    "#     all_question_q_table = initialize_question_table()   ### Only change if change to a new person;\n",
    "#     save_all_question_q_table()\n",
    "#     print('initialize the q tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state in choose action:  0\n",
      "ITEM A 5\n",
      "Item number:  5\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 4\n",
      "question_mask [0, 1, 1, 1, 0, 1]\n",
      "score in log []\n",
      "Have you taken days off recently?\n",
      "  Have you taken days off recently?\n",
      "   Have you taken days off recently?\n",
      "[' Yes, I have', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yes, I have', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 0.9 q_predict 1.1529\n",
      "new_question_q_table after update      0     1     2      3        4     5\n",
      "0  0.0  1.00  1.00  1.000  1.12761  1.00\n",
      "1  0.0  1.00  1.00  1.000  1.00000  1.00\n",
      "2  0.0  1.00  1.00  1.071  1.00000  0.99\n",
      "3  0.0  2.71  1.00  1.000  1.00000  1.00\n",
      "4  0.0  1.00  0.99  0.900  1.00000  0.99\n",
      "5  0.0  1.00  1.09  0.990  1.00000  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  4\n",
      "Question Action 1\n",
      "question_mask [0, 0, 1, 1, 0, 1]\n",
      "score in log [0]\n",
      "Already answered, get reward from history\n",
      "q_target 0.9 q_predict 1.0\n",
      "new_question_q_table after update      0     1     2      3        4     5\n",
      "0  0.0  1.00  1.00  1.000  1.12761  1.00\n",
      "1  0.0  1.00  1.00  1.000  1.00000  1.00\n",
      "2  0.0  1.00  1.00  1.071  1.00000  0.99\n",
      "3  0.0  2.71  1.00  1.000  1.00000  1.00\n",
      "4  0.0  0.99  0.99  0.900  1.00000  0.99\n",
      "5  0.0  1.00  1.09  0.990  1.00000  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 3\n",
      "question_mask [0, 0, 1, 0, 0, 1]\n",
      "score in log []\n",
      "Are you showing up for work or school?\n",
      "  Are you showing up for work or school?\n",
      "   Are you showing up for work or school?\n",
      "[' Yes, I am', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yes, I am', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 0.9 q_predict 1.0\n",
      "new_question_q_table after update      0     1     2      3        4     5\n",
      "0  0.0  1.00  1.00  1.000  1.12761  1.00\n",
      "1  0.0  1.00  1.00  0.990  1.00000  1.00\n",
      "2  0.0  1.00  1.00  1.071  1.00000  0.99\n",
      "3  0.0  2.71  1.00  1.000  1.00000  1.00\n",
      "4  0.0  0.99  0.99  0.900  1.00000  0.99\n",
      "5  0.0  1.00  1.09  0.990  1.00000  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  3\n",
      "Question Action 5\n",
      "question_mask [0, 0, 1, 0, 0, 0]\n",
      "score in log []\n",
      "Are you showing up to your plans?\n",
      "  Are you showing up to your plans?\n",
      "   Are you showing up to your plans?\n",
      "['Yes', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yes', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 0.9810000000000001 q_predict 1.0\n",
      "new_question_q_table after update      0     1     2      3        4       5\n",
      "0  0.0  1.00  1.00  1.000  1.12761  1.0000\n",
      "1  0.0  1.00  1.00  0.990  1.00000  1.0000\n",
      "2  0.0  1.00  1.00  1.071  1.00000  0.9900\n",
      "3  0.0  2.71  1.00  1.000  1.00000  0.9981\n",
      "4  0.0  0.99  0.99  0.900  1.00000  0.9900\n",
      "5  0.0  1.00  1.09  0.990  1.00000  1.0000\n",
      "***************************************************************************************************\n",
      "state in choose action:  5\n",
      "Question Action 2\n",
      "question_mask [0, 0, 0, 0, 0, 0]\n",
      "score in log []\n",
      "How's your eating habits? Do you have your meals on time?\n",
      "  How's your eating habits? Do you have your meals on time?\n",
      "   How's your eating habits? Do you have your meals on time?\n",
      "['I did not have my meals on time', '']\n",
      "[['DLA_5_eat', 2]]\n",
      "[['DLA_5_eat', 2]] ['I did not have my meals on time', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_5_eat', 2]\n",
      "label DLA_5_eat\n",
      "1\n",
      "Score:  2\n",
      " You did not have your meals on time.\n",
      "You mentioned that  You did not have your meals on time. Can you tell me more?\n",
      "7\n",
      "8  I didn't have time today to eat lunch.\n",
      " I'm sorry to hear that you didn't have time to eat lunch. I understand that sometimes life can be really busy. But it's important to make time for meals so you can stay healthy. You can try to pack a lunch or eat something quick.\n",
      "therapist_resp in evaluate  I'm sorry to hear that you didn't have time to eat lunch. I understand that sometimes life can be really busy. But it's important to make time for meals so you can stay healthy. You can try to pack a lunch or eat something quick.\n",
      "9\n",
      "check1\n",
      "5\n",
      "5\n",
      "item_number, question_number, valid: 5 2 1\n",
      "last_question in evaluate_result:   I'm sorry to hear that you didn't have time to eat lunch. I understand that sometimes life can be really busy. But it's important to make time for meals so you can stay healthy. You can try to pack a lunch or eat something quick.\n",
      " I'm sorry to hear that you didn't have time to eat lunch. I understand that sometimes life can be really busy. But it's important to make time for meals so you can stay healthy. You can try to pack a lunch or eat something quick.\n",
      "DLA_result: [['DLA_5_eat', 2]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  I'm sorry to hear that you didn't have time to eat lunch. I understand that sometimes life can be really busy. But it's important to make time for meals so you can stay healthy. You can try to pack a lunch or eat something quick.\n",
      "q_target 10 q_predict 1.09\n",
      "new_question_q_table after update      0     1      2      3        4       5\n",
      "0  0.0  1.00  1.000  1.000  1.12761  1.0000\n",
      "1  0.0  1.00  1.000  0.990  1.00000  1.0000\n",
      "2  0.0  1.00  1.000  1.071  1.00000  0.9900\n",
      "3  0.0  2.71  1.000  1.000  1.00000  0.9981\n",
      "4  0.0  0.99  0.990  0.900  1.00000  0.9900\n",
      "5  0.0  1.00  1.981  0.990  1.00000  1.0000\n",
      "question_q_table after update      0     1      2      3        4       5\n",
      "0  0.0  1.00  1.000  1.000  1.12761  1.0000\n",
      "1  0.0  1.00  1.000  0.990  1.00000  1.0000\n",
      "2  0.0  1.00  1.000  1.071  1.00000  0.9900\n",
      "3  0.0  2.71  1.000  1.000  1.00000  0.9981\n",
      "4  0.0  0.99  0.990  0.900  1.00000  0.9900\n",
      "5  0.0  1.00  1.981  0.990  1.00000  1.0000\n",
      "all_question_q_table[S]      0     1      2      3        4       5\n",
      "0  0.0  1.00  1.000  1.000  1.12761  1.0000\n",
      "1  0.0  1.00  1.000  0.990  1.00000  1.0000\n",
      "2  0.0  1.00  1.000  1.071  1.00000  0.9900\n",
      "3  0.0  2.71  1.000  1.000  1.00000  0.9981\n",
      "4  0.0  0.99  0.990  0.900  1.00000  0.9900\n",
      "5  0.0  1.00  1.981  0.990  1.00000  1.0000\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 0.0, 0.0, 0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  5\n",
      "ITEM A 1\n",
      "Item number:  1\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 3\n",
      "question_mask [0, 1, 1, 0, 1]\n",
      "score in log []\n",
      " Have you been following your doctor's orders?\n",
      " Have you been following your doctor's orders?\n",
      " I'm sorry to hear that you didn't have time to eat lunch. I understand that sometimes life can be really busy. But it's important to make time for meals so you can stay healthy. You can try to pack a lunch or eat something quick.  Have you been following your doctor's orders?\n",
      " I'm sorry to hear that you didn't have time to eat lunch. I understand that sometimes life can be really busy. But it's important to make time for meals so you can stay healthy. You can try to pack a lunch or eat something quick.   Have you been following your doctor's orders?\n",
      "['Yes', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yes', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 1.71 q_predict 2.0\n",
      "new_question_q_table after update      0     1     2      3     4\n",
      "0  0.0  1.00  0.99  1.971  0.99\n",
      "1  0.0  1.00  1.00  0.990  1.90\n",
      "2  0.0  1.00  1.00  0.990  1.00\n",
      "3  0.0  1.19  1.90  1.000  1.00\n",
      "4  0.0  0.99  1.00  1.000  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  3\n",
      "Question Action 2\n",
      "question_mask [0, 1, 0, 0, 1]\n",
      "score in log []\n",
      "How has your mood been? What do you feel about your mood?\n",
      "  How has your mood been? What do you feel about your mood?\n",
      "   How has your mood been? What do you feel about your mood?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am OK', '']\n",
      "[['DLA_1_mood', 0]]\n",
      "[['DLA_1_mood', 0]] ['I am OK', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_1_mood', 0]\n",
      "label DLA_1_mood\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "1\n",
      "4\n",
      "item_number, question_number, valid: 1 2 1\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "DLA_result: [['DLA_1_mood', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "q_target 0.9 q_predict 1.9\n",
      "new_question_q_table after update      0     1     2      3     4\n",
      "0  0.0  1.00  0.99  1.971  0.99\n",
      "1  0.0  1.00  1.00  0.990  1.90\n",
      "2  0.0  1.00  1.00  0.990  1.00\n",
      "3  0.0  1.19  1.80  1.000  1.00\n",
      "4  0.0  0.99  1.00  1.000  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  2\n",
      "Question Action 1\n",
      "question_mask [0, 0, 0, 0, 1]\n",
      "score in log []\n",
      "Have you lost or gained a significant amount of weight recently?\n",
      " Have you lost or gained a significant amount of weight recently?\n",
      "  Have you lost or gained a significant amount of weight recently?\n",
      "['Nope', '']\n",
      "[['DLA', 'No']]\n",
      "[['DLA', 'No']] ['Nope', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'No']\n",
      " \n",
      "DLA_result: [['DLA', 'No']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 1.71 q_predict 1.0\n",
      "new_question_q_table after update      0      1     2      3     4\n",
      "0  0.0  1.000  0.99  1.971  0.99\n",
      "1  0.0  1.000  1.00  0.990  1.90\n",
      "2  0.0  1.071  1.00  0.990  1.00\n",
      "3  0.0  1.190  1.80  1.000  1.00\n",
      "4  0.0  0.990  1.00  1.000  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 4\n",
      "question_mask [0, 0, 0, 0, 0]\n",
      "score in log []\n",
      "Have you been seeing your medical providers as needed?\n",
      "  Have you been seeing your medical providers as needed?\n",
      "   Have you been seeing your medical providers as needed?\n",
      "['Yeap', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yeap', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 10 q_predict 1.9\n",
      "new_question_q_table after update      0      1     2      3     4\n",
      "0  0.0  1.000  0.99  1.971  0.99\n",
      "1  0.0  1.000  1.00  0.990  2.71\n",
      "2  0.0  1.071  1.00  0.990  1.00\n",
      "3  0.0  1.190  1.80  1.000  1.00\n",
      "4  0.0  0.990  1.00  1.000  1.00\n",
      "question_q_table after update      0      1     2      3     4\n",
      "0  0.0  1.000  0.99  1.971  0.99\n",
      "1  0.0  1.000  1.00  0.990  2.71\n",
      "2  0.0  1.071  1.00  0.990  1.00\n",
      "3  0.0  1.190  1.80  1.000  1.00\n",
      "4  0.0  0.990  1.00  1.000  1.00\n",
      "all_question_q_table[S]      0      1     2      3     4\n",
      "0  0.0  1.000  0.99  1.971  0.99\n",
      "1  0.0  1.000  1.00  0.990  2.71\n",
      "2  0.0  1.071  1.00  0.990  1.00\n",
      "3  0.0  1.190  1.80  1.000  1.00\n",
      "4  0.0  0.990  1.00  1.000  1.00\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 0.0, 0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  1\n",
      "ITEM A 2\n",
      "Item number:  2\n",
      "Have you been taking care of your living space?\n",
      "   Have you been taking care of your living space?\n",
      "['Of course, yes', '']\n",
      "[['DLA', 'Yes']]\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  2\n",
      "ITEM A 19\n",
      "Item number:  19\n",
      "Already answered, get reward from history\n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  19\n",
      "ITEM A 10\n",
      "Item number:  10\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 2\n",
      "question_mask [0, 1, 0, 1]\n",
      "score in log [2, 2]\n",
      "Already answered, get reward from history\n",
      "q_target 2.9 q_predict 1.19\n",
      "new_question_q_table after update      0     1      2     3\n",
      "0  0.0  0.99  1.361  1.00\n",
      "1  0.0  1.00  1.000  0.99\n",
      "2  0.0  1.00  1.000  0.99\n",
      "3  0.0  1.90  1.900  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  2\n",
      "Question Action 2\n",
      "question_mask [0, 1, 0, 1]\n",
      "score in log [2, 2]\n",
      "Already answered, get reward from history\n",
      "q_target 2.9 q_predict 0.0\n",
      "new_question_q_table after update      0     1      2     3\n",
      "0  0.0  0.99  1.361  1.00\n",
      "1  0.0  1.00  1.000  0.99\n",
      "2  0.0  1.00  1.290  0.99\n",
      "3  0.0  1.90  1.900  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  2\n",
      "Question Action 1\n",
      "question_mask [0, 0, 0, 1]\n",
      "score in log []\n",
      "Do you often drink alone?\n",
      "  Do you often drink alone?\n",
      "   Do you often drink alone?\n",
      "['Sometimes I drink alone', '']\n",
      "[['DLA_10_alcohol', 1]]\n",
      "[['DLA_10_alcohol', 1]] ['Sometimes I drink alone', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_10_alcohol', 1]\n",
      "label DLA_10_alcohol\n",
      "1\n",
      "Score:  1\n",
      "check1\n",
      "10\n",
      "3\n",
      "item_number, question_number, valid: 10 1 1\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "DLA_result: [['DLA_10_alcohol', 1]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "q_target 1.9 q_predict 1.0\n",
      "new_question_q_table after update      0     1      2     3\n",
      "0  0.0  0.99  1.361  1.00\n",
      "1  0.0  1.00  1.000  0.99\n",
      "2  0.0  1.09  1.290  0.99\n",
      "3  0.0  1.90  1.900  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 1\n",
      "question_mask [0, 0, 0, 1]\n",
      "score in log [1]\n",
      "Already answered, get reward from history\n",
      "q_target 1.891 q_predict 0.0\n",
      "new_question_q_table after update      0       1      2     3\n",
      "0  0.0  0.9900  1.361  1.00\n",
      "1  0.0  1.1891  1.000  0.99\n",
      "2  0.0  1.0900  1.290  0.99\n",
      "3  0.0  1.9000  1.900  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 3\n",
      "question_mask [0, 0, 0, 0]\n",
      "score in log []\n",
      "Do you use any substance and what's the frequency of using?\n",
      " Do you use any substance and what's the frequency of using?\n",
      "  Do you use any substance and what's the frequency of using?\n",
      "['I never have drugs', '']\n",
      "[['DLA_10_drug', 0]]\n",
      "[['DLA_10_drug', 0]] ['I never have drugs', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_10_drug', 0]\n",
      "label DLA_10_drug\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "10\n",
      "3\n",
      "item_number, question_number, valid: 10 3 1\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "DLA_result: [['DLA_10_drug', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "q_target 10 q_predict 0.99\n",
      "new_question_q_table after update      0       1      2      3\n",
      "0  0.0  0.9900  1.361  1.000\n",
      "1  0.0  1.1891  1.000  1.891\n",
      "2  0.0  1.0900  1.290  0.990\n",
      "3  0.0  1.9000  1.900  1.000\n",
      "question_q_table after update      0       1      2      3\n",
      "0  0.0  0.9900  1.361  1.000\n",
      "1  0.0  1.1891  1.000  1.891\n",
      "2  0.0  1.0900  1.290  0.990\n",
      "3  0.0  1.9000  1.900  1.000\n",
      "all_question_q_table[S]      0       1      2      3\n",
      "0  0.0  0.9900  1.361  1.000\n",
      "1  0.0  1.1891  1.000  1.891\n",
      "2  0.0  1.0900  1.290  0.990\n",
      "3  0.0  1.9000  1.900  1.000\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [2.0, 2.0, 1.0, 1.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 16.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  10\n",
      "ITEM A 15\n",
      "Item number:  15\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 1\n",
      "question_mask [0, 0, 1]\n",
      "score in log []\n",
      "Are you productive at work or school?\n",
      " Are you productive at work or school?\n",
      "  Are you productive at work or school?\n",
      "['I think so', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['I think so', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 1.71 q_predict 0.99\n",
      "new_question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  1.90\n",
      "2  0.0  1.900  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 1\n",
      "question_mask [0, 0, 1]\n",
      "score in log [0]\n",
      "Already answered, get reward from history\n",
      "q_target 1.71 q_predict 0.0\n",
      "new_question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.171  1.90\n",
      "2  0.0  1.900  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 2\n",
      "question_mask [0, 0, 0]\n",
      "score in log []\n",
      "Are you motivated to work or study?\n",
      "  Are you motivated to work or study?\n",
      "   Are you motivated to work or study?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am not motivated recently', '']\n",
      "[['DLA_15_productivity', 2]]\n",
      "[['DLA_15_productivity', 2]] ['I am not motivated recently', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_15_productivity', 2]\n",
      "label DLA_15_productivity\n",
      "0\n",
      "Score:  2\n",
      " You are not motivated recently.\n",
      "You mentioned that  You are not motivated recently. Can you tell me more?\n",
      "7\n",
      "8 I was too busy and want to have a break.\n",
      "\n",
      "\n",
      "I understand that you feel like you need a break. But it's important to stay motivated and continue your work. You can talk to your family members, friends, or therapist to help you out.\n",
      "therapist_resp in evaluate \n",
      "\n",
      "I understand that you feel like you need a break. But it's important to stay motivated and continue your work. You can talk to your family members, friends, or therapist to help you out.\n",
      "9\n",
      "check1\n",
      "15\n",
      "2\n",
      "item_number, question_number, valid: 15 1 0\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "I understand that you feel like you need a break. But it's important to stay motivated and continue your work. You can talk to your family members, friends, or therapist to help you out.\n",
      "\n",
      "\n",
      "I understand that you feel like you need a break. But it's important to stay motivated and continue your work. You can talk to your family members, friends, or therapist to help you out.\n",
      "DLA_result: [['DLA_15_productivity', 2]]\n",
      "valid: 0\n",
      "DLA_terminate: 0\n",
      "   Are you motivated to work or study?\n",
      "['No', '']\n",
      "[['DLA', 'No']]\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "If score > 1 for direct yes/no/stop\n",
      " You're not motivated to work or study.\n",
      " can you explain it more to me?\n",
      "It seems that  You're not motivated to work or study.  can you explain it more to me?\n",
      "4\n",
      "5  I was too busy and want to have a break.\n",
      " I can understand that you feel exhausted from work or school. However, it's important to find ways to relax and take a break. Maybe you can go out with friends or family members. Or you can find time to do something you enjoy.\n",
      "therapist_resp in evaluate Y/N  I can understand that you feel exhausted from work or school. However, it's important to find ways to relax and take a break. Maybe you can go out with friends or family members. Or you can find time to do something you enjoy.\n",
      "6\n",
      "Evaluate DLA:  ['DLA', 'No']\n",
      "last question  I can understand that you feel exhausted from work or school. However, it's important to find ways to relax and take a break. Maybe you can go out with friends or family members. Or you can find time to do something you enjoy.\n",
      "q_target 10 q_predict 1.9\n",
      "new_question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.171  2.71\n",
      "2  0.0  1.900  1.00\n",
      "question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.171  2.71\n",
      "2  0.0  1.900  1.00\n",
      "all_question_q_table[S]      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.171  2.71\n",
      "2  0.0  1.900  1.00\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  15\n",
      "ITEM A 13\n",
      "Item number:  13\n",
      "Other than family members, who do you consider as your close support?\n",
      " I can understand that you feel exhausted from work or school. However, it's important to find ways to relax and take a break. Maybe you can go out with friends or family members. Or you can find time to do something you enjoy.  Other than family members, who do you consider as your close support?\n",
      "['I have my friends as my support', '']\n",
      "[['DLA_13_support', 0]]\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_13_support', 0]\n",
      "label DLA_13_support\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "13\n",
      "2\n",
      "item_number, question_number, valid: 13 1 1\n",
      "last_question in evaluate_result:  \n",
      "DLA_result: [['DLA_13_support', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  13\n",
      "ITEM A 3\n",
      "Item number:  3\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 2\n",
      "question_mask [0, 1, 0]\n",
      "score in log []\n",
      "Have you expressed feelings to others?\n",
      " Have you expressed feelings to others?\n",
      "  Have you expressed feelings to others?\n",
      "['Yes', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yes', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 2.439 q_predict 1.242\n",
      "new_question_q_table after update      0     1       2\n",
      "0  0.0  1.00  1.3617\n",
      "1  0.0  1.00  1.0000\n",
      "2  0.0  2.71  1.2900\n",
      "***************************************************************************************************\n",
      "state in choose action:  2\n",
      "Question Action 1\n",
      "question_mask [0, 0, 0]\n",
      "score in log []\n",
      "Have you been talking to other people?\n",
      "  Have you been talking to other people?\n",
      "   Have you been talking to other people?\n",
      "['I talked to my colleagues', '']\n",
      "[['DLA_3_talk', 0]]\n",
      "[['DLA_3_talk', 0]] ['I talked to my colleagues', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_3_talk', 0]\n",
      "label DLA_3_talk\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "3\n",
      "2\n",
      "item_number, question_number, valid: 3 1 1\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "DLA_result: [['DLA_3_talk', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "q_target 10 q_predict 2.71\n",
      "new_question_q_table after update      0      1       2\n",
      "0  0.0  1.000  1.3617\n",
      "1  0.0  1.000  1.0000\n",
      "2  0.0  3.439  1.2900\n",
      "question_q_table after update      0      1       2\n",
      "0  0.0  1.000  1.3617\n",
      "1  0.0  1.000  1.0000\n",
      "2  0.0  3.439  1.2900\n",
      "all_question_q_table[S]      0      1       2\n",
      "0  0.0  1.000  1.3617\n",
      "1  0.0  1.000  1.0000\n",
      "2  0.0  3.439  1.2900\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  3\n",
      "ITEM A 18\n",
      "Item number:  18\n",
      "Already answered, get reward from history\n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  18\n",
      "ITEM A 11\n",
      "Item number:  11\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 1\n",
      "question_mask [0, 0, 1]\n",
      "score in log []\n",
      "What is you hobby?\n",
      " What is you hobby?\n",
      "  What is you hobby?\n",
      "['I like to go shopping', '']\n",
      "[['DLA_11_hobbies', 0]]\n",
      "[['DLA_11_hobbies', 0]] ['I like to go shopping', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_11_hobbies', 0]\n",
      "label DLA_11_hobbies\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "11\n",
      "2\n",
      "item_number, question_number, valid: 11 1 1\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "DLA_result: [['DLA_11_hobbies', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "q_target 1.71 q_predict 0.99\n",
      "new_question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  1.90\n",
      "2  0.0  1.900  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 2\n",
      "question_mask [0, 0, 0]\n",
      "score in log []\n",
      "Have you done any creative work recently?\n",
      " Have you done any creative work recently?\n",
      "  Have you done any creative work recently?\n",
      "['Yes', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yes', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 10 q_predict 1.9\n",
      "new_question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  2.71\n",
      "2  0.0  1.900  1.00\n",
      "question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  2.71\n",
      "2  0.0  1.900  1.00\n",
      "all_question_q_table[S]      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  2.71\n",
      "2  0.0  1.900  1.00\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  11\n",
      "ITEM A 16\n",
      "Item number:  16\n",
      "What kind of coping do you use to calm yourself?\n",
      "   What kind of coping do you use to calm yourself?\n",
      "['I do yoga and meditation to calm me', '']\n",
      "[['DLA_16_coping', 0]]\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_16_coping', 0]\n",
      "label DLA_16_coping\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "16\n",
      "1\n",
      "Only one question in this item.\n",
      "item_number, question_number, valid: 16 1 1\n",
      "last_question in evaluate_result:  \n",
      "DLA_result: [['DLA_16_coping', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  16\n",
      "ITEM A 9\n",
      "Item number:  9\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 1\n",
      "question_mask [0, 0, 1]\n",
      "score in log []\n",
      "Do you feel supported by your family?\n",
      " Do you feel supported by your family?\n",
      "  Do you feel supported by your family?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yes', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 1.71 q_predict 0.99\n",
      "new_question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  1.90\n",
      "2  0.0  1.900  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 2\n",
      "question_mask [0, 0, 0]\n",
      "score in log []\n",
      "How's your relationship with your family? Do you get along with your family?\n",
      "  How's your relationship with your family? Do you get along with your family?\n",
      "   How's your relationship with your family? Do you get along with your family?\n",
      "['I get along well with my family', '']\n",
      "[['DLA_9_family', 0]]\n",
      "[['DLA_9_family', 0]] ['I get along well with my family', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_9_family', 0]\n",
      "label DLA_9_family\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "9\n",
      "2\n",
      "item_number, question_number, valid: 9 2 1\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "DLA_result: [['DLA_9_family', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "q_target 10 q_predict 1.9\n",
      "new_question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  2.71\n",
      "2  0.0  1.900  1.00\n",
      "question_q_table after update      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  2.71\n",
      "2  0.0  1.900  1.00\n",
      "all_question_q_table[S]      0      1     2\n",
      "0  0.0  1.062  0.99\n",
      "1  0.0  1.000  2.71\n",
      "2  0.0  1.900  1.00\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  9\n",
      "ITEM A 14\n",
      "Item number:  14\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 3\n",
      "question_mask [0, 1, 1, 0]\n",
      "score in log []\n",
      "Do you try to avoid risky sexual behaviours?\n",
      " Do you try to avoid risky sexual behaviours?\n",
      "  Do you try to avoid risky sexual behaviours?\n",
      "['Of course yes', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Of course yes', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 1.71 q_predict 1.0\n",
      "new_question_q_table after update      0     1      2      3\n",
      "0  0.0  1.00  0.981  1.071\n",
      "1  0.0  1.00  1.000  1.900\n",
      "2  0.0  0.99  1.000  0.990\n",
      "3  0.0  1.90  1.000  1.000\n",
      "***************************************************************************************************\n",
      "state in choose action:  3\n",
      "Question Action 1\n",
      "question_mask [0, 0, 1, 0]\n",
      "score in log []\n",
      "Are you sexually active?\n",
      "Are you sexually active?\n",
      "  Are you sexually active?\n",
      "   Are you sexually active?\n",
      "['Yes', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['Yes', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 0.9 q_predict 1.9\n",
      "new_question_q_table after update      0     1      2      3\n",
      "0  0.0  1.00  0.981  1.071\n",
      "1  0.0  1.00  1.000  1.900\n",
      "2  0.0  0.99  1.000  0.990\n",
      "3  0.0  1.80  1.000  1.000\n",
      "***************************************************************************************************\n",
      "state in choose action:  1\n",
      "Question Action 2\n",
      "question_mask [0, 0, 0, 0]\n",
      "score in log []\n",
      "If you have partners, do you feel comfortable with your partner or partners?\n",
      "  If you have partners, do you feel comfortable with your partner or partners?\n",
      "   If you have partners, do you feel comfortable with your partner or partners?\n",
      "['I feel comfortable with my partners', '']\n",
      "[['DLA_14_comfortable', 0]]\n",
      "[['DLA_14_comfortable', 0]] ['I feel comfortable with my partners', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_14_comfortable', 0]\n",
      "label DLA_14_comfortable\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "14\n",
      "3\n",
      "item_number, question_number, valid: 14 2 1\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "DLA_result: [['DLA_14_comfortable', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "q_target 10 q_predict 1.0\n",
      "new_question_q_table after update      0     1      2      3\n",
      "0  0.0  1.00  0.981  1.071\n",
      "1  0.0  1.00  1.900  1.900\n",
      "2  0.0  0.99  1.000  0.990\n",
      "3  0.0  1.80  1.000  1.000\n",
      "question_q_table after update      0     1      2      3\n",
      "0  0.0  1.00  0.981  1.071\n",
      "1  0.0  1.00  1.900  1.900\n",
      "2  0.0  0.99  1.000  0.990\n",
      "3  0.0  1.80  1.000  1.000\n",
      "all_question_q_table[S]      0     1      2      3\n",
      "0  0.0  1.00  0.981  1.071\n",
      "1  0.0  1.00  1.900  1.900\n",
      "2  0.0  0.99  1.000  0.990\n",
      "3  0.0  1.80  1.000  1.000\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  14\n",
      "ITEM A 7\n",
      "Item number:  7\n",
      "Already answered, get reward from history\n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  7\n",
      "ITEM A 12\n",
      "Item number:  12\n",
      "What dou you do in your neighborhood or community?\n",
      "  What dou you do in your neighborhood or community?\n",
      "['I go outside for coffee', '']\n",
      "[['DLA_12_community', 0]]\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_12_community', 0]\n",
      "label DLA_12_community\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "12\n",
      "1\n",
      "Only one question in this item.\n",
      "item_number, question_number, valid: 12 1 1\n",
      "last_question in evaluate_result:  \n",
      "DLA_result: [['DLA_12_community', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  12\n",
      "ITEM A 6\n",
      "Item number:  6\n",
      "How's your finance? Do you have any concerns about your finance?\n",
      "  How's your finance? Do you have any concerns about your finance?\n",
      "['No', '']\n",
      "[['DLA', 'No']]\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'No']\n",
      "DLA_result: [['DLA', 'No']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  6\n",
      "ITEM A 4\n",
      "Item number:  4\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 2\n",
      "question_mask [0, 1, 0]\n",
      "score in log []\n",
      "Are you risk-taking when you make decisions?\n",
      "  Are you risk-taking when you make decisions?\n",
      "   Are you risk-taking when you make decisions?\n",
      "['I am not risk-taking recently', '']\n",
      "[['DLA_4_risk', 0]]\n",
      "[['DLA_4_risk', 0]] ['I am not risk-taking recently', '']\n",
      "check\n",
      "3\n",
      "Evaluate DLA:  ['DLA_4_risk', 0]\n",
      "label DLA_4_risk\n",
      "1\n",
      "Score:  0\n",
      "check1\n",
      "4\n",
      "2\n",
      "item_number, question_number, valid: 4 2 1\n",
      "last_question in evaluate_result:  \n",
      "\n",
      "DLA_result: [['DLA_4_risk', 0]]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question \n",
      "q_target 0.9 q_predict 1.0\n",
      "new_question_q_table after update      0     1     2\n",
      "0  0.0  0.99  0.99\n",
      "1  0.0  1.00  1.90\n",
      "2  0.0  1.00  1.00\n",
      "***************************************************************************************************\n",
      "state in choose action:  2\n",
      "Question Action 1\n",
      "question_mask [0, 0, 0]\n",
      "score in log []\n",
      "Are you currently safe?\n",
      " Are you currently safe?\n",
      "  Are you currently safe?\n",
      "['I think so', '']\n",
      "[['DLA', 'Yes']]\n",
      "[['DLA', 'Yes']] ['I think so', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      " \n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 10 q_predict 1.0\n",
      "new_question_q_table after update      0     1     2\n",
      "0  0.0  0.99  0.99\n",
      "1  0.0  1.00  1.90\n",
      "2  0.0  1.90  1.00\n",
      "question_q_table after update      0     1     2\n",
      "0  0.0  0.99  0.99\n",
      "1  0.0  1.00  1.90\n",
      "2  0.0  1.90  1.00\n",
      "all_question_q_table[S]      0     1     2\n",
      "0  0.0  0.99  0.99\n",
      "1  0.0  1.00  1.90\n",
      "2  0.0  1.90  1.00\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  4\n",
      "ITEM A 17\n",
      "Item number:  17\n",
      "***************************************************************************************************\n",
      "state in choose action:  0\n",
      "Question Action 3\n",
      "question_mask [0, 1, 1, 0]\n",
      "score in log []\n",
      "Are you involved in any legal issues recently?\n",
      "  Are you involved in any legal issues recently?\n",
      "   Are you involved in any legal issues recently?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not recently', '']\n",
      "[['DLA', 'No']]\n",
      "[['DLA', 'No']] ['Not recently', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'No']\n",
      " \n",
      "DLA_result: [['DLA', 'No']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 1.71 q_predict 1.0\n",
      "new_question_q_table after update      0     1    2      3\n",
      "0  0.0  0.99  1.0  1.071\n",
      "1  0.0  1.00  1.0  0.990\n",
      "2  0.0  1.00  1.0  1.000\n",
      "3  0.0  1.00  1.9  1.000\n",
      "***************************************************************************************************\n",
      "state in choose action:  3\n",
      "Question Action 2\n",
      "question_mask [0, 1, 0, 0]\n",
      "score in log []\n",
      "Have you been arrested recently?\n",
      "  Have you been arrested recently?\n",
      "   Have you been arrested recently?\n",
      "['No', '']\n",
      "[['DLA', 'No']]\n",
      "[['DLA', 'No']] ['No', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'No']\n",
      " \n",
      "DLA_result: [['DLA', 'No']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 0.9 q_predict 1.9\n",
      "new_question_q_table after update      0     1    2      3\n",
      "0  0.0  0.99  1.0  1.071\n",
      "1  0.0  1.00  1.0  0.990\n",
      "2  0.0  1.00  1.0  1.000\n",
      "3  0.0  1.00  1.8  1.000\n",
      "***************************************************************************************************\n",
      "state in choose action:  2\n",
      "Question Action 2\n",
      "question_mask [0, 1, 0, 0]\n",
      "score in log [0]\n",
      "Already answered, get reward from history\n",
      "q_target 0.9 q_predict 0.0\n",
      "new_question_q_table after update      0     1     2      3\n",
      "0  0.0  0.99  1.00  1.071\n",
      "1  0.0  1.00  1.00  0.990\n",
      "2  0.0  1.00  1.09  1.000\n",
      "3  0.0  1.00  1.80  1.000\n",
      "***************************************************************************************************\n",
      "state in choose action:  2\n",
      "Question Action 1\n",
      "question_mask [0, 0, 0, 0]\n",
      "score in log []\n",
      "Do you self-harm?\n",
      "  Do you self-harm?\n",
      "   Do you self-harm?\n",
      "['No', '']\n",
      "[['DLA', 'No']]\n",
      "[['DLA', 'No']] ['No', '']\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'No']\n",
      " \n",
      "DLA_result: [['DLA', 'No']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "q_target 10 q_predict 1.0\n",
      "new_question_q_table after update      0     1     2      3\n",
      "0  0.0  0.99  1.00  1.071\n",
      "1  0.0  1.00  1.00  0.990\n",
      "2  0.0  1.90  1.09  1.000\n",
      "3  0.0  1.00  1.80  1.000\n",
      "question_q_table after update      0     1     2      3\n",
      "0  0.0  0.99  1.00  1.071\n",
      "1  0.0  1.00  1.00  0.990\n",
      "2  0.0  1.90  1.09  1.000\n",
      "3  0.0  1.00  1.80  1.000\n",
      "all_question_q_table[S]      0     1     2      3\n",
      "0  0.0  0.99  1.00  1.071\n",
      "1  0.0  1.00  1.00  0.990\n",
      "2  0.0  1.90  1.09  1.000\n",
      "3  0.0  1.00  1.80  1.000\n",
      "___________________________________________________________________________________________________\n",
      "question_reward:  [0.0, 0.0, 0.0, 10]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 10.0\n",
      "ITEM DLA_terminate 0\n",
      "state in choose action:  17\n",
      "ITEM A 8\n",
      "Item number:  8\n",
      "Are you able to make decisions yourself?\n",
      "   Are you able to make decisions yourself?\n",
      "['I believe so', '']\n",
      "[['DLA', 'Yes']]\n",
      "check\n",
      "3\n",
      "1 + There is direct yes/no/stop to the question\n",
      "2\n",
      "Evaluate DLA:  ['DLA', 'Yes']\n",
      "DLA_result: [['DLA', 'Yes']]\n",
      "valid: 1\n",
      "DLA_terminate: 0\n",
      "last question  \n",
      "question_reward:  [0.0]\n",
      "DLA_terminate 0\n",
      "ITEM openai_res 0.0\n",
      "ITEM DLA_terminate 0\n",
      "Q1: Thank you for answering all the questions. According to your previous responses, you have issues in Dimension 11: Maintaining Regular Schedule for Eating, Dimension 21: Tobacco Usage, Dimension 30: Productivity at Work or School, Dimension 31: Motivation at Work or School, Which dimension do you want to work on today? Please speak out the dimension number, for example, 1.\n",
      "Thank you for answering all the questions. According to your previous responses, you have issues in Dimension 11: Maintaining Regular Schedule for Eating, Dimension 21: Tobacco Usage, Dimension 30: Productivity at Work or School, Dimension 31: Motivation at Work or School, Which dimension do you want to work on today? Please speak out the dimension number, for example, 1.\n",
      "user_dimension1: 21\n",
      "Q2:  Let's work on Dimension 21. From my record, you mentio Can you try to identify any unhelpful thoughts you have that contribute to this situation?\n",
      " Let's work on Dimension 21. From my record, you mentio Can you try to identify any unhelpful thoughts you have that contribute to this situation?\n",
      "user_thought: I smoke recently.\n",
      "Can you challenge your thought?\n",
      "Q3: Can you challenge your thought?\n",
      "user_challenge: I want to live in a healthy life style.\n",
      " You want to live in a healthy life style.\n",
      "Q4: You mentioned that:  You want to live in a healthy life style. to challenge your thought. Now, what is another way of thinking about this situation?\n",
      "You mentioned that:  You want to live in a healthy life style. to challenge your thought. Now, what is another way of thinking about this situation?\n",
      "user_new_way: I might reduce the frequency of smoking.\n",
      "Q5: Congratulation, you figure out a way for yourself. You also work well in dimensions including: Dimension 10: Following Regular Schedule for Bedtime and Sleeping Enough, Dimension 5: Organizing Personal Possessions and Doing Housework, and Dimension 29: Managing Sexual Safety. Please reach out to your primary care or your therapist if you have further problems or emergencies.Goodbye. We will followup later. 886\n",
      "Congratulation, you figure out a way for yourself. You also work well in dimensions including: Dimension 10: Following Regular Schedule for Bedtime and Sleeping Enough, Dimension 5: Organizing Personal Possessions and Doing Housework, and Dimension 29: Managing Sexual Safety. Please reach out to your primary care or your therapist if you have further problems or emergencies.Goodbye. We will followup later. 886\n",
      "total 19\n",
      "----\n",
      "4\n",
      "DLA_1_weight []\n",
      "DLA_1_mood []\n",
      "DLA_1_medication []\n",
      "DLA_1_care []\n",
      "----\n",
      "1\n",
      "DLA_2_house []\n",
      "----\n",
      "2\n",
      "DLA_3_talk []\n",
      "DLA_3_emo []\n",
      "----\n",
      "2\n",
      "DLA_4_safe []\n",
      "DLA_4_risk []\n",
      "----\n",
      "5\n",
      "DLA_5_sleep []\n",
      "DLA_5_eat []\n",
      "DLA_5_work []\n",
      "DLA_5_work_dayoff []\n",
      "DLA_5_showup []\n",
      "----\n",
      "1\n",
      "DLA_6_finance []\n",
      "----\n",
      "1\n",
      "DLA_7_nutrition []\n",
      "----\n",
      "1\n",
      "DLA_8_problem []\n",
      "----\n",
      "2\n",
      "DLA_9_support []\n",
      "DLA_9_family []\n",
      "----\n",
      "3\n",
      "DLA_10_alcohol []\n",
      "DLA_10_ciga []\n",
      "DLA_10_drug []\n",
      "----\n",
      "2\n",
      "DLA_11_hobbies []\n",
      "DLA_11_creativity []\n",
      "----\n",
      "1\n",
      "DLA_12_community []\n",
      "----\n",
      "2\n",
      "DLA_13_support []\n",
      "DLA_13_social []\n",
      "----\n",
      "3\n",
      "DLA_14_sex []\n",
      "DLA_14_comfortable []\n",
      "DLA_14_protection []\n",
      "----\n",
      "2\n",
      "DLA_15_productivity []\n",
      "DLA_15_motivation []\n",
      "----\n",
      "1\n",
      "DLA_16_coping []\n",
      "----\n",
      "3\n",
      "DLA_17_sib []\n",
      "DLA_17_arrest []\n",
      "DLA_17_legal []\n",
      "----\n",
      "1\n",
      "DLA_18_hygiene []\n",
      "----\n",
      "1\n",
      "DLA_21_sports []\n",
      "[['DLA_1_weight', [], []], ['DLA_1_mood', [], []], ['DLA_1_medication', [], []], ['DLA_1_care', [], []], ['DLA_2_house', [], []], ['DLA_3_talk', [], []], ['DLA_3_emo', [], []], ['DLA_4_safe', [], []], ['DLA_4_risk', [], []], ['DLA_5_sleep', [], []], ['DLA_5_eat', [], []], ['DLA_5_work', [], []], ['DLA_5_work_dayoff', [], []], ['DLA_5_showup', [], []], ['DLA_6_finance', [], []], ['DLA_7_nutrition', [], []], ['DLA_8_problem', [], []], ['DLA_9_support', [], []], ['DLA_9_family', [], []], ['DLA_10_alcohol', [], []], ['DLA_10_ciga', [], []], ['DLA_10_drug', [], []], ['DLA_11_hobbies', [], []], ['DLA_11_creativity', [], []], ['DLA_12_community', [], []], ['DLA_13_support', [], []], ['DLA_13_social', [], []], ['DLA_14_sex', [], []], ['DLA_14_comfortable', [], []], ['DLA_14_protection', [], []], ['DLA_15_productivity', [], []], ['DLA_15_motivation', [], []], ['DLA_16_coping', [], []], ['DLA_17_sib', [], []], ['DLA_17_arrest', [], []], ['DLA_17_legal', [], []], ['DLA_18_hygiene', [], []], ['DLA_21_sports', [], []]]\n"
     ]
    }
   ],
   "source": [
    "all_question_mask = initialize_question_mask()\n",
    "all_question_q_table = load_all_question_q_table()    ### Only change if change to a new person;\n",
    "\n",
    "f = open(filename)\n",
    "question_lib = json.load(f)\n",
    "\n",
    "item_q_table = initialize_q_table(ITEM_N_STATES, ITEM_ACTIONS)\n",
    "new_response = []\n",
    "# # speaker = US_speakers[np.random.randint(len(US_speakers))]\n",
    "last_question = \" \"\n",
    "\n",
    "for episode in range(1):\n",
    "    cnt = 0 \n",
    "    S = 0\n",
    "    is_terminated = False\n",
    "    item_mask = [0] + [1] * (ITEM_N_STATES-1)\n",
    "    new_q_table = item_q_table.copy()\n",
    "    while not is_terminated:\n",
    "#         print(\"item_mask: \", item_mask)\n",
    "        A = choose_action(S, item_q_table, item_mask, ITEM_N_STATES, ITEM_ACTIONS)\n",
    "        print(\"ITEM A\", A)\n",
    "        item_mask[int(A)] = 0\n",
    "        openai_res, DLA_terminate = ask_question(int(A), all_question_mask)\n",
    "#         openai_res = np.random.randint(5)\n",
    "#         DLA_terminate = 0\n",
    "        print(\"ITEM openai_res\", openai_res)\n",
    "        print(\"ITEM DLA_terminate\", DLA_terminate)\n",
    "        S_, R = get_env_feedback(S, A, openai_res, DLA_terminate, item_mask)  # take action & get next state and reward\n",
    "        q_predict = item_q_table.loc[S, A]\n",
    "        if S_ != 'terminal':\n",
    "            q_target = R + GAMMA * item_q_table.iloc[S_, :].max()   # next state is not terminal\n",
    "        else:\n",
    "            q_target = R     # next state is terminal\n",
    "            is_terminated = True    # terminate this episode\n",
    "\n",
    "        new_q_table.loc[S, A] += ALPHA * (q_target - q_predict)  # update\n",
    "        S = S_  # move to next state  \n",
    "        cnt += 1\n",
    "        if DLA_terminate == 1:\n",
    "            is_terminated = True\n",
    "            save_filename = \"question_lib_v2_\" + str(subjectID) + \"_\"+ str(int(time.time()))+\".json\"\n",
    "            with open(save_filename, 'w') as f:\n",
    "                json.dump(question_lib, f)\n",
    "            log_question(\"Goodbye. We will do the screening in another time. 886\")\n",
    "#             is_terminated = True\n",
    "#             log_question(\"Sounds like it's not a good time to talk. Do you want to continue? Say yes if you want to continue. Say no if you want to quit the current session.\")\n",
    "#             user_correction = get_resp_log()\n",
    "#             print(type(user_correction))\n",
    "#             user_correction = user_correction.replace(\".\", \" \")\n",
    "#             user_correction = user_correction.replace(\",\", \" \")\n",
    "#             user_correction = user_correction.replace(\"?\", \" \")\n",
    "#             user_correction = user_correction.split(\" \")\n",
    "#             user_correction =[ i.lower() for i in user_correction]\n",
    "#             if \"no\" in user_correction:\n",
    "#                 log_question(\"Goodbye. We will do the screening in another time. 886\")\n",
    "#                 is_terminated = True\n",
    "    if is_terminated == True:\n",
    "        save_filename = \"question_lib_v2_\" + str(subjectID) + \"_\"+ str(int(time.time()))+\".json\"\n",
    "        with open(save_filename, 'w') as f:\n",
    "            json.dump(question_lib, f)\n",
    "        if DLA_terminate == 1:\n",
    "            pass\n",
    "        else:\n",
    "            proceed_MI_CBT(save_filename) ## MI and CBT as the summary\n",
    "    print(\"total\", cnt)\n",
    "    item_q_table = new_q_table.copy()\n",
    "\n",
    "\n",
    "#clear out the original one for next use\n",
    "for i in range(1, len(question_lib)+1):\n",
    "    for ind in range(1, len(question_lib[str(i)])+1):\n",
    "        question_lib[str(i)][str(ind)][\"notes\"] = []\n",
    "        question_lib[str(i)][str(ind)][\"score\"] = []\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(question_lib, f)\n",
    "\n",
    "#save q table:\n",
    "    \n",
    "save_all_question_q_table()\n",
    "generate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceed_MI_CBT(save_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_all_question_q_table()\n",
    "# generate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dla",
   "language": "python",
   "name": "dla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
